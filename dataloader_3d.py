# -*- coding: utf-8 -*-
"""
3D Box Detection DataLoader
åŠ è½½processedæ•°æ®ï¼šRGBXYZå›¾åƒ(npz) + 3D Boxæ ‡æ³¨(json)
"""

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
import yaml
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import random
from collections.abc import Sequence, Mapping

def load_config(config_path: str = "data_config.yaml") -> Dict:
    """åŠ è½½æ•°æ®é…ç½®æ–‡ä»¶ - å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§é—®é¢˜"""
    print(f"âš ï¸  è­¦å‘Š: load_configå·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨ç»Ÿä¸€é…ç½®æ–‡ä»¶training_config.yaml")
    return {}

# ä»segment_dataset.pyå¤åˆ¶çš„å˜æ¢ç±»
class GridSample(object):
    def __init__(self, grid_size=0.05, mode="train"):
        self.grid_size = grid_size
        self.hash = self.fnv_hash_vec
        # ä¸ºæ‰€æœ‰æ¨¡å¼è®¾ç½®keysï¼ŒåŒ…æ‹¬valæ¨¡å¼
        self.keys = ("coord",)

    def __call__(self, data_dict):
        assert "coord" in data_dict.keys()
        scaled_coord = data_dict["coord"] / np.array(self.grid_size)
        grid_coord = np.floor(scaled_coord).astype(int)
        min_coord = grid_coord.min(0)
        grid_coord -= min_coord
        scaled_coord -= min_coord
        min_coord = min_coord * np.array(self.grid_size)
        key = self.hash(grid_coord)
        idx_sort = np.argsort(key)
        key_sort = key[idx_sort]
        _, inverse, count = np.unique(key_sort, return_inverse=True, return_counts=True)
        idx_select = (
            np.cumsum(np.insert(count, 0, 0)[0:-1])
            + np.random.randint(0, count.max(), count.size) % count
        )
        idx_unique = idx_sort[idx_select]
        data_dict["grid_coord"] = grid_coord[idx_unique]
        for key in self.keys:
            data_dict[key] = data_dict[key][idx_unique]
        
        # ä¿æŒåƒç´ åæ ‡æ˜ å°„å…³ç³»
        if "pixel_coords" in data_dict:
            data_dict["pixel_coords"] = data_dict["pixel_coords"][idx_unique]
        
        return data_dict
    
    @staticmethod
    def fnv_hash_vec(arr):
        assert arr.ndim == 2
        arr = arr.copy()
        arr = arr.astype(np.uint64, copy=False)
        hashed_arr = np.uint64(14695981039346656037) * np.ones(
            arr.shape[0], dtype=np.uint64
        )
        for j in range(arr.shape[1]):
            hashed_arr *= np.uint64(1099511628211)
            hashed_arr = np.bitwise_xor(hashed_arr, arr[:, j])
        return hashed_arr

class ToTensor(object):
    def __call__(self, data):
        if isinstance(data, torch.Tensor):
            return data
        elif isinstance(data, str):
            return data
        elif isinstance(data, int):
            return torch.LongTensor([data])
        elif isinstance(data, float):
            return torch.FloatTensor([data])
        elif isinstance(data, np.ndarray) and np.issubdtype(data.dtype, bool):
            return torch.from_numpy(data)
        elif isinstance(data, np.ndarray) and np.issubdtype(data.dtype, np.integer):
            return torch.from_numpy(data).long()
        elif isinstance(data, np.ndarray) and np.issubdtype(data.dtype, np.floating):
            return torch.from_numpy(data).float()
        elif isinstance(data, Mapping):
            result = {sub_key: self(item) for sub_key, item in data.items()}
            return result
        elif isinstance(data, Sequence):
            result = [self(item) for item in data]
            return result
        else:
            raise TypeError(f"type {type(data)} cannot be converted to tensor.")

class Collect(object):
    def __init__(self, keys, offset_keys_dict=None, **kwargs):
        if offset_keys_dict is None:
            offset_keys_dict = dict(offset="coord")
        self.keys = keys
        self.offset_keys = offset_keys_dict
        self.kwargs = kwargs

    def __call__(self, data_dict):
        data = dict()
        if isinstance(self.keys, str):
            self.keys = [self.keys]
        
        for key in self.keys:
            if key in data_dict:
                data[key] = data_dict[key]
        
        for key, value in self.offset_keys.items():
            if value in data_dict:
                # offsetåº”è¯¥æ˜¯ç´¯ç§¯åç§»é‡ï¼Œå¯¹äºå•ä¸ªæ ·æœ¬ï¼Œoffsetå°±æ˜¯[0, num_points]
                num_points = data_dict[value].shape[0]
                data[key] = torch.tensor([0, num_points], dtype=torch.long)
        
        for name, keys in self.kwargs.items():
            name = name.replace("_keys", "")
            assert isinstance(keys, Sequence)
            if len(keys) > 3: 
                keys = [keys]
            # å¦‚æœåªæœ‰ä¸€ä¸ªkeyï¼Œç›´æ¥ä½¿ç”¨è¯¥keyçš„æ•°æ®
            if len(keys) == 1:
                data[name] = data_dict[keys[0]].float()
            else:
                data[name] = torch.cat([data_dict[key].float() for key in keys], dim=1)
        
        # ä¿æŒåƒç´ åæ ‡æ˜ å°„å…³ç³»
        if "pixel_coords" in data_dict:
            data["pixel_coords"] = data_dict["pixel_coords"]
        
        return data

class RandomCrop(object):
    def __init__(self, point_max=80000, continuous_ranges=None, random_fluctuation=0.1):
        self.point_max = point_max
        self.continuous_ranges = continuous_ranges or {
            'x': [0.5, 2.5],
            'y': [-2.0, 2.0], 
            'z': [-1.5, 1.5]
        }
        self.random_fluctuation = random_fluctuation  # 0.1mçš„éšæœºæ³¢åŠ¨

    def __call__(self, data_dict):
        point_max = self.point_max
        assert "coord" in data_dict.keys()
        
        # å¦‚æœç‚¹äº‘æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œè¿›è¡ŒåŸºäºèŒƒå›´çš„åˆ‡å‰²
        if data_dict["coord"].shape[0] > point_max:
            # ç”Ÿæˆå¸¦éšæœºæ³¢åŠ¨çš„åˆ‡å‰²èŒƒå›´
            crop_ranges = {}
            for axis, (min_val, max_val) in self.continuous_ranges.items():
                # æ·»åŠ 0.1mçš„éšæœºæ³¢åŠ¨
                fluctuation = np.random.uniform(-self.random_fluctuation, self.random_fluctuation)
                min_crop = min_val + fluctuation
                max_crop = max_val + fluctuation
                
                # ç¡®ä¿èŒƒå›´ä»ç„¶åˆç†
                min_crop = max(min_crop, min_val - self.random_fluctuation)
                max_crop = min(max_crop, max_val + self.random_fluctuation)
                
                crop_ranges[axis] = [min_crop, max_crop]
            
            # æ ¹æ®åˆ‡å‰²èŒƒå›´è¿‡æ»¤ç‚¹äº‘
            coord = data_dict["coord"]
            valid_mask = np.ones(coord.shape[0], dtype=bool)
            
            # å¯¹æ¯ä¸ªè½´è¿›è¡ŒèŒƒå›´è¿‡æ»¤
            for i, axis in enumerate(['x', 'y', 'z']):
                if axis in crop_ranges:
                    min_val, max_val = crop_ranges[axis]
                    axis_mask = (coord[:, i] >= min_val) & (coord[:, i] <= max_val)
                    valid_mask = valid_mask & axis_mask
            
            # å¦‚æœè¿‡æ»¤åçš„ç‚¹äº‘ä»ç„¶å¤ªå¤šï¼Œéšæœºé‡‡æ ·
            if valid_mask.sum() > point_max:
                valid_indices = np.where(valid_mask)[0]
                selected_indices = np.random.choice(valid_indices, point_max, replace=False)
                idx_crop = selected_indices
            else:
                # å¦‚æœè¿‡æ»¤åçš„ç‚¹äº‘ä¸å¤Ÿï¼Œä½¿ç”¨æ‰€æœ‰æœ‰æ•ˆç‚¹
                idx_crop = np.where(valid_mask)[0]
            
            # åº”ç”¨åˆ‡å‰²
            if "coord" in data_dict.keys():
                data_dict["coord"] = data_dict["coord"][idx_crop]
            if "grid_coord" in data_dict.keys():
                data_dict["grid_coord"] = data_dict["grid_coord"][idx_crop]
            
            # ä¿æŒåƒç´ åæ ‡æ˜ å°„å…³ç³»
            if "pixel_coords" in data_dict:
                data_dict["pixel_coords"] = data_dict["pixel_coords"][idx_crop]
                
        return data_dict

class RandomDropout(object):
    def __init__(self, dropout_ratio=0.2, dropout_application_ratio=0.5):
        self.dropout_ratio = dropout_ratio
        self.dropout_application_ratio = dropout_application_ratio

    def __call__(self, data_dict):
        if random.random() < self.dropout_application_ratio:
            n = len(data_dict["coord"])
            # ç¡®ä¿è‡³å°‘ä¿ç•™1ä¸ªç‚¹ï¼Œé¿å…ç©ºç‚¹äº‘
            keep_count = max(1, int(n * (1 - self.dropout_ratio)))
            idx = np.random.choice(n, keep_count, replace=False)
            if "coord" in data_dict.keys():
                data_dict["coord"] = data_dict["coord"][idx]
            
            # ä¿æŒåƒç´ åæ ‡æ˜ å°„å…³ç³»
            if "pixel_coords" in data_dict:
                data_dict["pixel_coords"] = data_dict["pixel_coords"][idx]
        return data_dict

class Box3DDataset(Dataset):
    """3D Boxæ£€æµ‹æ•°æ®é›†"""
    
    def __init__(
        self,
        data_root: str,
        config_path: str = "data_config.yaml",  # å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§
        stage: str = "train",  # train, val, test
        # å¿…éœ€å‚æ•°ï¼ˆä»è®­ç»ƒé…ç½®ä¼ å…¥ï¼‰
        max_boxes: Optional[int] = None,
        image_size: Optional[Tuple[int, int]] = None,
        continuous_ranges: Optional[Dict] = None,
        augmentation_config: Optional[Dict] = None,
        # å…¶ä»–å¯é€‰å‚æ•°
        augment: Optional[bool] = None,
        augment_intensity: Optional[float] = None,
        pad_id: Optional[int] = None,
        **kwargs
    ):
        """
        Args:
            data_root: processedæ•°æ®æ ¹ç›®å½•è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§ï¼‰
            stage: è®­ç»ƒé˜¶æ®µ (train/val/test)
            max_boxes: æœ€å¤§boxæ•°é‡
            image_size: å›¾åƒå°ºå¯¸
            continuous_ranges: è¿ç»­å€¼èŒƒå›´é…ç½®
            augmentation_config: æ•°æ®å¢å¼ºé…ç½®
            å…¶ä»–å‚æ•°: å¯é€‰å‚æ•°ä¼šè¦†ç›–é»˜è®¤è®¾ç½®
        """
        self.data_root = Path(data_root)
        self.stage = stage
        
        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œè€Œä¸æ˜¯è¯»å–ä¸å­˜åœ¨çš„é…ç½®æ–‡ä»¶
        if config_path != "data_config.yaml":
            print(f"âš ï¸  è­¦å‘Š: config_pathå‚æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨ç»Ÿä¸€é…ç½®æ–‡ä»¶")
        
        # è®¾ç½®å‚æ•°ï¼ˆä¼˜å…ˆçº§ï¼šç›´æ¥å‚æ•° > é»˜è®¤å€¼ï¼‰
        self.max_boxes = max_boxes if max_boxes is not None else 10
        self.image_size = image_size if image_size is not None else (640, 640)
        self.pad_id = pad_id if pad_id is not None else -1
        
        # ğŸ”§ ä¿®å¤ï¼šæ•°æ®å¢å¼ºè®¾ç½® - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„augmentation_config
        if augmentation_config is not None:
            self.augmentation_config = augmentation_config
            self.aug_config = augmentation_config  # ä¿æŒå‘åå…¼å®¹
            self.augment = augment if augment is not None else augmentation_config.get('enabled', False)
            base_intensity = augmentation_config.get('intensity', 1.0)
            self.augment_intensity = augment_intensity if augment_intensity is not None else base_intensity
        else:
            # å›é€€åˆ°é»˜è®¤å€¼
            self.augmentation_config = {}
            self.aug_config = {}
            self.augment = augment if augment is not None else False
            self.augment_intensity = augment_intensity if augment_intensity is not None else 1.0
        
        # ğŸ”§ ä¿®å¤ï¼šè¿ç»­å€¼èŒƒå›´ - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„continuous_ranges
        if continuous_ranges is not None:
            self.continuous_range_x = continuous_ranges.get('x', [0.5, 2.5])
            self.continuous_range_y = continuous_ranges.get('y', [-2, 2])
            self.continuous_range_z = continuous_ranges.get('z', [-1.5, 1.5])
            self.continuous_range_w = continuous_ranges.get('w', [0.3, 0.7])
            self.continuous_range_h = continuous_ranges.get('h', [0.3, 0.7])
            self.continuous_range_l = continuous_ranges.get('l', [0.3, 0.7])
        else:
            # ä½¿ç”¨é»˜è®¤å€¼
            self.continuous_range_x = [0.5, 2.5]
            self.continuous_range_y = [-2, 2]
            self.continuous_range_z = [-1.5, 1.5]
            self.continuous_range_w = [0.3, 0.7]
            self.continuous_range_h = [0.3, 0.7]
            self.continuous_range_l = [0.3, 0.7]
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        if self.augment:
            print(f"ğŸ¨ æ•°æ®å¢å¼ºå·²å¯ç”¨ (å¼ºåº¦: {self.augment_intensity})")
        else:
            print(f"âŒ æ•°æ®å¢å¼ºå·²ç¦ç”¨")
        
        # ç‚¹äº‘å˜æ¢ï¼Œå‚è€ƒsegment_dataset.py
        self.grid = GridSample(grid_size=0.05, mode=stage)
        self.totensor = ToTensor()
        
        # ä½¿ç”¨continuous_rangesè¿›è¡Œç‚¹äº‘åˆ‡å‰²
        # ä»augmentation_configä¸­è·å–è£å‰ªå‚æ•°
        cropping_config = self.augmentation_config.get('point_cloud', {}).get('cropping', {})
        point_max = cropping_config.get('max_points', 50000)
        random_fluctuation = cropping_config.get('random_fluctuation', 0.1)
        
        self.crop = RandomCrop(
            point_max=point_max,
            continuous_ranges={
                'x': self.continuous_range_x,
                'y': self.continuous_range_y,
                'z': self.continuous_range_z
            },
            random_fluctuation=random_fluctuation
        )
        self.drop = RandomDropout(dropout_ratio=0.3)
        
        # æ‰«ææ•°æ®æ–‡ä»¶
        self.samples = self._scan_data()
        
        print(f"Box3DDataset: æ‰¾åˆ° {len(self.samples)} ä¸ªæ ·æœ¬")
        print(f"  æ•°æ®æ ¹ç›®å½•: {self.data_root}")
        print(f"  å›¾åƒå°ºå¯¸: {self.image_size}")
        print(f"  æœ€å¤§boxæ•°: {self.max_boxes}")
        print(f"  æ•°æ®å¢å¼º: {self.augment} (å¼ºåº¦: {self.augment_intensity})")
    
    def _scan_data(self) -> List[Dict]:
        """æ‰«ææ•°æ®ç›®å½•ï¼Œè¿”å›æ ·æœ¬åˆ—è¡¨"""
        samples = []
        
        # æ ¹æ®stageç¡®å®šè¦åŠ è½½çš„æ•°æ®å­ç›®å½•
        if self.stage == "train":
            data_subdir = self.data_root / "train"
        elif self.stage == "val":
            data_subdir = self.data_root / "val"
        elif self.stage == "test":
            data_subdir = self.data_root / "test"
        else:
            # é»˜è®¤åŠ è½½trainæ–‡ä»¶å¤¹
            data_subdir = self.data_root / "train"
            print(f"è­¦å‘Š: æœªçŸ¥çš„stage '{self.stage}'ï¼Œé»˜è®¤åŠ è½½trainæ–‡ä»¶å¤¹")
        
        # æ£€æŸ¥æ•°æ®å­ç›®å½•æ˜¯å¦å­˜åœ¨
        if not data_subdir.exists():
            print(f"é”™è¯¯: æ•°æ®å­ç›®å½•ä¸å­˜åœ¨: {data_subdir}")
            return samples
        
        # éå†æ•°æ®å­ç›®å½•ä¸­çš„æ‰€æœ‰ç¼–å·æ–‡ä»¶å¤¹
        for folder in sorted(data_subdir.iterdir()):
            if not folder.is_dir():
                continue
            
            # æ¥å—çº¯æ•°å­—å’Œå¸¦ä¸‹åˆ’çº¿çš„æ•°å­—æ–‡ä»¶å¤¹å (å¦‚ 0000, 0000_2)
            folder_name = folder.name
            if not (folder_name.isdigit() or (folder_name.replace('_', '').isdigit() and '_' in folder_name)):
                continue
                
            folder_name = folder.name
            npz_file = folder / f"{folder_name}.npz"
            json_file = folder / f"{folder_name}.json"
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if npz_file.exists() and json_file.exists():
                samples.append({
                    'folder_name': folder_name,
                    'npz_file': str(npz_file),
                    'json_file': str(json_file)
                })
            else:
                print(f"è­¦å‘Š: æ–‡ä»¶å¤¹ {folder_name} ç¼ºå°‘å¿…è¦æ–‡ä»¶")
        
        return samples
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def _load_rgbxyz_image(self, npz_file: str) -> np.ndarray:
        """åŠ è½½RGBXYZå›¾åƒæ•°æ®"""
        try:
            data = np.load(npz_file)
            rgbxyz = data['rgbxyz']  # Shape: (H, W, 6) - [R, G, B, X, Y, Z]
            data.close()
            return rgbxyz
        except Exception as e:
            print(f"åŠ è½½å›¾åƒå¤±è´¥ {npz_file}: {e}")
            # è¿”å›ç©ºå›¾åƒ
            return np.zeros((*self.image_size, 6), dtype=np.float32)
    
    def _load_boxes(self, json_file: str) -> List[Dict]:
        """åŠ è½½3D boxæ ‡æ³¨"""
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
            return data.get('boxes', [])
        except Exception as e:
            print(f"åŠ è½½æ ‡æ³¨å¤±è´¥ {json_file}: {e}")
            return []
    
    def _normalize_coordinates(self, boxes: List[Dict]) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """æå–boxåæ ‡å’Œå°ºå¯¸ï¼Œè¿›è¡ŒèŒƒå›´è£å‰ªï¼ŒåŒæ—¶æå–æ—‹è½¬ä¿¡æ¯ï¼ˆä¿æŒåŸå§‹ç‰©ç†æ•°å€¼ï¼Œä¸å½’ä¸€åŒ–ï¼‰"""
        if not boxes:
            # è¿”å›ç©ºæ•°ç»„
            return (np.array([]), np.array([]), np.array([]), 
                   np.array([]), np.array([]), np.array([]), 
                   np.array([]).reshape(0, 4))  # æ—‹è½¬å››å…ƒæ•°
        
        # æå–åæ ‡ã€å°ºå¯¸å’Œæ—‹è½¬
        positions = np.array([box['position'] for box in boxes])  # (N, 3)
        sizes = np.array([box['size'] for box in boxes])  # (N, 3)
        rotations = np.array([box['rotation'] for box in boxes])  # (N, 4) - quaternion [x,y,z,w]
        
        # åˆ†ç¦»xyzåæ ‡å’Œwhlå°ºå¯¸
        x = positions[:, 0]
        y = positions[:, 1] 
        z = positions[:, 2]
        w = sizes[:, 1]  # width
        h = sizes[:, 2]  # height
        l = sizes[:, 0]  # length
        
        # ğŸ”§ ä¿®å¤ï¼šä¸åšå½’ä¸€åŒ–ï¼Œä¿æŒåŸå§‹æ•°å€¼
        # åªè¿›è¡ŒèŒƒå›´æ£€æŸ¥å’Œè£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
        x_clipped = np.clip(x, self.continuous_range_x[0], self.continuous_range_x[1])
        y_clipped = np.clip(y, self.continuous_range_y[0], self.continuous_range_y[1])
        z_clipped = np.clip(z, self.continuous_range_z[0], self.continuous_range_z[1])
        w_clipped = np.clip(w, self.continuous_range_w[0], self.continuous_range_w[1])
        h_clipped = np.clip(h, self.continuous_range_h[0], self.continuous_range_h[1])
        l_clipped = np.clip(l, self.continuous_range_l[0], self.continuous_range_l[1])
        
        return x_clipped, y_clipped, z_clipped, w_clipped, h_clipped, l_clipped, rotations
    
    def _pad_sequences(self, x, y, z, w, h, l, rotations) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """å°†åºåˆ—padåˆ°å›ºå®šé•¿åº¦"""
        current_len = len(x)
        
        if current_len == 0:
            # å¦‚æœæ²¡æœ‰boxï¼Œè¿”å›å…¨paddingçš„tensor
            identity_quat = np.array([0.0, 0.0, 0.0, 1.0])  # å•ä½å››å…ƒæ•° (x,y,z,w)
            return (torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.from_numpy(np.tile(identity_quat, (self.max_boxes, 1))).float())
        
        if current_len > self.max_boxes:
            # å¦‚æœè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œéšæœºé‡‡æ ·
            indices = np.random.choice(current_len, self.max_boxes, replace=False)
            x = x[indices]
            y = y[indices]
            z = z[indices]
            w = w[indices]
            h = h[indices]
            l = l[indices]
            rotations = rotations[indices]
        else:
            # å¦‚æœä¸è¶³æœ€å¤§é•¿åº¦ï¼Œè¿›è¡Œpadding
            pad_len = self.max_boxes - current_len
            x = np.concatenate([x, np.full(pad_len, self.pad_id)])
            y = np.concatenate([y, np.full(pad_len, self.pad_id)])
            z = np.concatenate([z, np.full(pad_len, self.pad_id)])
            w = np.concatenate([w, np.full(pad_len, self.pad_id)])
            h = np.concatenate([h, np.full(pad_len, self.pad_id)])
            l = np.concatenate([l, np.full(pad_len, self.pad_id)])
            
            # ä¸ºæ—‹è½¬æ•°æ®paddingä½¿ç”¨å•ä½å››å…ƒæ•°
            identity_quat = np.array([0.0, 0.0, 0.0, 1.0])  # å•ä½å››å…ƒæ•° (x,y,z,w)
            pad_rotations = np.tile(identity_quat, (pad_len, 1))
            rotations = np.concatenate([rotations, pad_rotations], axis=0)
        
        return (torch.from_numpy(x).float(),
               torch.from_numpy(y).float(),
               torch.from_numpy(z).float(),
               torch.from_numpy(w).float(),
               torch.from_numpy(h).float(),
               torch.from_numpy(l).float(),
               torch.from_numpy(rotations).float())
    
    def _augment_data(self, rgbxyz: np.ndarray, boxes: List[Dict]) -> Tuple[np.ndarray, List[Dict]]:
        """æ•°æ®å¢å¼º - åŒ…æ‹¬å›¾åƒå™ªç‚¹å’Œç‚¹äº‘å™ªå£°"""
        if not self.augment:
            return rgbxyz, boxes
        
        # æ³¨æ„ï¼šæ•°æ®æ˜¯ä»æ–‡ä»¶æ–°åŠ è½½çš„ï¼Œæ— éœ€å¤åˆ¶
        # ä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œä»ç„¶å¤åˆ¶boxesï¼ˆå› ä¸ºå®ƒä»¬åŒ…å«åµŒå¥—çš„numpyæ•°ç»„ï¼‰
        boxes = [box.copy() for box in boxes]
        for box in boxes:
            box['position'] = box['position'].copy()
            box['size'] = box['size'].copy()
        
        # 2. RGBå›¾åƒå¢å¼º
        rgb_enh = self.aug_config.get('rgb_enhancement', {})
        
        # äº®åº¦è°ƒæ•´
        brightness_cfg = rgb_enh.get('brightness', {})
        if brightness_cfg.get('enabled', True) and random.random() < brightness_cfg.get('probability', 0.7):
            factor_range = brightness_cfg.get('factor_range', [0.8, 1.2])
            brightness_factor = random.uniform(*factor_range)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] * brightness_factor, 0, 255)
        
        # å¯¹æ¯”åº¦è°ƒæ•´
        contrast_cfg = rgb_enh.get('contrast', {})
        if contrast_cfg.get('enabled', True) and random.random() < contrast_cfg.get('probability', 0.7):
            factor_range = contrast_cfg.get('factor_range', [0.8, 1.2])
            contrast_factor = random.uniform(*factor_range)
            mean_rgb = rgbxyz[:, :, :3].mean()
            rgbxyz[:, :, :3] = np.clip((rgbxyz[:, :, :3] - mean_rgb) * contrast_factor + mean_rgb, 0, 255)
        
        # è‰²è°ƒåç§»
        hue_cfg = rgb_enh.get('hue', {})  # ä¿®æ­£é…ç½®é”®å
        if hue_cfg.get('enabled', True) and random.random() < hue_cfg.get('probability', 0.7):
            shift_range = hue_cfg.get('shift_range', [-10, 10])
            hue_shift = random.uniform(*shift_range)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] + hue_shift, 0, 255)
        
        # 3. RGBå›¾åƒå™ªç‚¹
        rgb_noise = self.aug_config.get('rgb_noise', {})
        
        # é«˜æ–¯å™ªå£°
        gaussian_cfg = rgb_noise.get('gaussian', {})
        if gaussian_cfg.get('enabled', True) and random.random() < gaussian_cfg.get('probability', 0.6):
            std_range = gaussian_cfg.get('std_range', [2, 8])
            noise_std = random.uniform(*std_range) * self.augment_intensity
            gaussian_noise = np.random.normal(0, noise_std, rgbxyz[:, :, :3].shape)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] + gaussian_noise, 0, 255)
        
        # æ¤’ç›å™ªå£°
        salt_pepper_cfg = rgb_noise.get('salt_pepper', {})
        if salt_pepper_cfg.get('enabled', True) and random.random() < salt_pepper_cfg.get('probability', 0.4):
            ratio_range = salt_pepper_cfg.get('ratio_range', [0.001, 0.01])
            noise_ratio = random.uniform(*ratio_range) * self.augment_intensity
            mask = np.random.random(rgbxyz[:, :, :3].shape) < noise_ratio
            rgbxyz[:, :, :3][mask] = np.random.choice([0, 255], size=mask.sum())
        
        # æ–‘ç‚¹å™ªå£°
        speckle_cfg = rgb_noise.get('speckle', {})
        if speckle_cfg.get('enabled', True) and random.random() < speckle_cfg.get('probability', 0.3):
            std_range = speckle_cfg.get('std_range', [0.05, 0.15])
            noise_std = random.uniform(*std_range) * self.augment_intensity
            speckle_noise = np.random.normal(0, noise_std, rgbxyz[:, :, :3].shape)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] * (1 + speckle_noise), 0, 255)
        

            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] * (1 + speckle_noise), 0, 255)
        
        # 4. ç‚¹äº‘(XYZ)å™ªå£°
        pc_config = self.aug_config.get('point_cloud', {})
        
        # XYZåæ ‡é«˜æ–¯å™ªå£°
        gaussian_cfg = pc_config.get('gaussian_noise', {})
        if gaussian_cfg.get('enabled', True) and random.random() < gaussian_cfg.get('probability', 0.7):
            std_ranges = gaussian_cfg.get('std_ranges', {'x': [0.01, 0.05], 'y': [0.01, 0.05], 'z': [0.005, 0.03]})
            xyz_noise_std = [
                random.uniform(*std_ranges.get('x', [0.01, 0.05])) * self.augment_intensity,
                random.uniform(*std_ranges.get('y', [0.01, 0.05])) * self.augment_intensity,
                random.uniform(*std_ranges.get('z', [0.005, 0.03])) * self.augment_intensity
            ]
            
            for i, std in enumerate(xyz_noise_std):
                noise = np.random.normal(0, std, rgbxyz[:, :, 3+i].shape)
                rgbxyz[:, :, 3+i] += noise
        
        # ç‚¹äº‘éšæœºä¸¢å¤±
        dropout_cfg = pc_config.get('dropout', {})
        if dropout_cfg.get('enabled', True) and random.random() < dropout_cfg.get('probability', 0.5):
            ratio_range = dropout_cfg.get('ratio_range', [0.001, 0.01])
            dropout_ratio = random.uniform(*ratio_range) * self.augment_intensity
            dropout_mask = np.random.random(rgbxyz[:, :, 3:6].shape[:2]) < dropout_ratio
            rgbxyz[dropout_mask, 3:6] = 0
        
        # æ·±åº¦é‡åŒ–å™ªå£°
        quant_cfg = pc_config.get('quantization', {})
        if quant_cfg.get('enabled', True) and random.random() < quant_cfg.get('probability', 0.4):
            step_range = quant_cfg.get('step_range', [0.005, 0.02])
            depth_quantization = random.uniform(*step_range) * self.augment_intensity
            # é¿å…é™¤é›¶é”™è¯¯
            if depth_quantization > 0:
                rgbxyz[:, :, 5] = np.round(rgbxyz[:, :, 5] / depth_quantization) * depth_quantization
        
        # ç³»ç»Ÿæ€§åç§»
        bias_cfg = pc_config.get('coordinate_bias', {})
        if bias_cfg.get('enabled', True) and random.random() < bias_cfg.get('probability', 0.3):
            bias_ranges = bias_cfg.get('bias_ranges', {'x': [-0.02, 0.02], 'y': [-0.02, 0.02], 'z': [-0.01, 0.01]})
            xyz_bias = [
                random.uniform(*bias_ranges.get('x', [-0.02, 0.02])) * self.augment_intensity,
                random.uniform(*bias_ranges.get('y', [-0.02, 0.02])) * self.augment_intensity,
                random.uniform(*bias_ranges.get('z', [-0.01, 0.01])) * self.augment_intensity
            ]
            for i, bias in enumerate(xyz_bias):
                rgbxyz[:, :, 3+i] += bias
        
        # 5. 3D Boxæ ‡æ³¨æ‰°åŠ¨
        box_pert = self.aug_config.get('box_augmentation', {})
        if box_pert.get('enabled', True) and random.random() < box_pert.get('probability', 0.2):
            pos_noise_cfg = box_pert.get('position_noise', {})
            size_noise_cfg = box_pert.get('size_noise', {})
            
            for box in boxes:
                # ä½ç½®æ‰°åŠ¨
                if pos_noise_cfg.get('enabled', True):
                    noise_ranges = pos_noise_cfg.get('noise_ranges', {'x': [-0.02, 0.02], 'y': [-0.02, 0.02], 'z': [-0.01, 0.01]})
                    position_noise = [
                        random.uniform(*noise_ranges.get('x', [-0.02, 0.02])),
                        random.uniform(*noise_ranges.get('y', [-0.02, 0.02])),
                        random.uniform(*noise_ranges.get('z', [-0.01, 0.01]))
                    ]
                    for i, noise in enumerate(position_noise):
                        box['position'][i] += noise
                        # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if i == 0:  # X
                            box['position'][i] = np.clip(box['position'][i], 
                                                       self.continuous_range_x[0], 
                                                       self.continuous_range_x[1])
                        elif i == 1:  # Y
                            box['position'][i] = np.clip(box['position'][i], 
                                                       self.continuous_range_y[0], 
                                                       self.continuous_range_y[1])
                        elif i == 2:  # Z
                            box['position'][i] = np.clip(box['position'][i], 
                                                       self.continuous_range_z[0], 
                                                       self.continuous_range_z[1])
                
                # å°ºå¯¸æ‰°åŠ¨
                if size_noise_cfg.get('enabled', True):
                    noise_ranges = size_noise_cfg.get('noise_ranges', {'w': [-0.01, 0.01], 'h': [-0.01, 0.01], 'l': [-0.01, 0.01]})
                    size_noise = [
                        random.uniform(*noise_ranges.get('w', [-0.01, 0.01])),
                        random.uniform(*noise_ranges.get('h', [-0.01, 0.01])),
                        random.uniform(*noise_ranges.get('l', [-0.01, 0.01]))
                    ]
                    for i, noise in enumerate(size_noise):
                        box['size'][i] += noise
                        # ç¡®ä¿å°ºå¯¸ä¸ºæ­£ä¸”åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if i == 0:  # width
                            box['size'][i] = np.clip(box['size'][i], 
                                                    self.continuous_range_w[0], 
                                                    self.continuous_range_w[1])
                        elif i == 1:  # height
                            box['size'][i] = np.clip(box['size'][i], 
                                                    self.continuous_range_h[0], 
                                                    self.continuous_range_h[1])
                        elif i == 2:  # length
                            box['size'][i] = np.clip(box['size'][i], 
                                                    self.continuous_range_l[0], 
                                                    self.continuous_range_l[1])
        
        return rgbxyz, boxes
    
    def _convert_xyz_to_point_cloud(self, xyz_data: np.ndarray) -> dict:
        """å°†XYZæ•°æ®è½¬æ¢ä¸ºç‚¹äº‘æ ¼å¼ï¼Œå¹¶ä¿æŒåƒç´ åæ ‡æ˜ å°„å…³ç³»"""
        H, W, _ = xyz_data.shape
        
        # åˆ›å»ºåƒç´ åæ ‡ç½‘æ ¼
        pixel_y, pixel_x = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')
        pixel_coords = np.stack([
            pixel_x.flatten(),  # Xåƒç´ åæ ‡
            pixel_y.flatten()   # Yåƒç´ åæ ‡
        ], axis=1)  # (H*W, 2) - åƒç´ åæ ‡
        
        # å±•å¹³å¹¶ç»„åˆåæ ‡ - ä½¿ç”¨PointTransformeræœŸæœ›çš„æ ¼å¼
        coord = np.stack([
            xyz_data[:, :, 0].flatten(),  # Xåæ ‡ï¼ˆæ¥è‡ªXYZæ•°æ®ï¼‰
            xyz_data[:, :, 1].flatten(),  # Yåæ ‡ï¼ˆæ¥è‡ªXYZæ•°æ®ï¼‰
            xyz_data[:, :, 2].flatten()   # Zåæ ‡ï¼ˆæ¥è‡ªXYZæ•°æ®ï¼‰
        ], axis=1)  # (H*W, 3) - è¿™æ˜¯PointTransformeræœŸæœ›çš„coordæ ¼å¼
        
        # è¿”å›data_dictæ ¼å¼ï¼Œå‚è€ƒsegment_dataset.py
        data_dict = {
            'coord': coord,  # (N, 3) - XYZåæ ‡
            'pixel_coords': pixel_coords,  # (N, 2) - å¯¹åº”çš„åƒç´ åæ ‡ [x, y]
            'name': 'point_cloud'  # å¯é€‰çš„åå­—
        }
        
        return data_dict
    
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """è·å–å•ä¸ªæ ·æœ¬"""
        sample = self.samples[idx]
        
        # åŠ è½½RGBXYZå›¾åƒ
        rgbxyz = self._load_rgbxyz_image(sample['npz_file'])  # (H, W, 6)
        
        # åŠ è½½3D boxæ ‡æ³¨
        boxes = self._load_boxes(sample['json_file'])
        
        # æ•°æ®å¢å¼º
        rgbxyz, boxes = self._augment_data(rgbxyz, boxes)
        
        # å½’ä¸€åŒ–åæ ‡å¹¶æå–æ—‹è½¬ä¿¡æ¯
        x, y, z, w, h, l, rotations = self._normalize_coordinates(boxes)
        
        # Padåºåˆ—åˆ°å›ºå®šé•¿åº¦
        x_padded, y_padded, z_padded, w_padded, h_padded, l_padded, rotations_padded = self._pad_sequences(x, y, z, w, h, l, rotations)
        
        # åˆ†ç¦»RGBå’Œç‚¹äº‘æ•°æ®
        rgb_image = rgbxyz[:, :, :3]  # (H, W, 3) - RGBé€šé“
        xyz_data = rgbxyz[:, :, 3:6]  # (H, W, 3) - XYZé€šé“
        
        # è½¬æ¢RGBå›¾åƒæ ¼å¼ï¼š(H, W, 3) -> (3, H, W)
        rgb_tensor = torch.from_numpy(rgb_image).permute(2, 0, 1).float()
        rgb_tensor = rgb_tensor / 255.0  # å½’ä¸€åŒ–RGBé€šé“åˆ°[0,1]
        
        # å¤„ç†ç‚¹äº‘æ•°æ®ï¼šå°†(H, W, 3)è½¬æ¢ä¸ºç‚¹äº‘æ ¼å¼
        point_cloud_dict = self._convert_xyz_to_point_cloud(xyz_data)
        
        # åº”ç”¨ç‚¹äº‘å˜æ¢ï¼Œå‚è€ƒsegment_dataset.pyçš„æµç¨‹
        if self.stage == "train":
            point_cloud_dict = self.drop(point_cloud_dict)
        point_cloud_dict = self.grid(point_cloud_dict)
        point_cloud_dict = self.crop(point_cloud_dict)
        point_cloud_dict = self.totensor(point_cloud_dict)
        # æ‰‹åŠ¨å¤„ç†ç‚¹äº‘æ•°æ®ï¼Œä¸ä½¿ç”¨Collectç±»
        # ç¡®ä¿coordå’Œgrid_coordå­˜åœ¨
        if 'coord' not in point_cloud_dict:
            raise ValueError("point_cloud_dictä¸­ç¼ºå°‘'coord'å­—æ®µ")
        if 'grid_coord' not in point_cloud_dict:
            raise ValueError("point_cloud_dictä¸­ç¼ºå°‘'grid_coord'å­—æ®µ")
        
        # ç”Ÿæˆoffset: [0, num_points]
        num_points = point_cloud_dict['coord'].shape[0]
        point_cloud_dict['offset'] = torch.tensor([0, num_points], dtype=torch.long)
        
        # ç”Ÿæˆfeat: ä½¿ç”¨coordä½œä¸ºç‰¹å¾
        point_cloud_dict['feat'] = point_cloud_dict['coord'].float()
        
        # æå–å¤„ç†åçš„ç‚¹äº‘æ•°æ®
        # point_cloud = point_cloud_dict['coord']  # (N, 3) - XYZåæ ‡
        
        # åˆå¹¶RGBå›¾åƒå’Œç‚¹äº‘æ•°æ®ï¼Œå‚è€ƒsegment_dataset.pyçš„æ ¼å¼
        result = {
            'rgb_image': rgb_tensor,    # (3, H, W) - RGBå›¾åƒ
            'x': x_padded,             # (max_boxes,)
            'y': y_padded,             # (max_boxes,)
            'z': z_padded,          # (max_boxes,)
            'w': w_padded,          # (max_boxes,)
            'h': h_padded,          # (max_boxes,)
            'l': l_padded,          # (max_boxes,)
            'rotations': rotations_padded,  # (max_boxes, 4) - å››å…ƒæ•°æ—‹è½¬
            'folder_name': sample['folder_name']  # ç”¨äºè°ƒè¯•
        }
        # print(f"point_cloud_dict: {point_cloud_dict['grid_coord'].shape}")
        # æ·»åŠ ç‚¹äº‘æ•°æ®å­—æ®µåˆ°ç»“æœä¸­
        result.update(point_cloud_dict)
        
        return result

def create_dataloader(
    data_root: str,
    config_path: str = "data_config.yaml",  # å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§
    stage: str = "train",
    batch_size: Optional[int] = None,
    shuffle: Optional[bool] = None,
    num_workers: Optional[int] = None,
    pin_memory: Optional[bool] = None,
    prefetch_factor: Optional[int] = None,
    persistent_workers: Optional[bool] = None,
    drop_last: Optional[bool] = None,
    **kwargs
) -> DataLoader:
    """åˆ›å»ºDataLoader - ç°åœ¨ä½¿ç”¨ç›´æ¥å‚æ•°è€Œä¸æ˜¯é…ç½®æ–‡ä»¶"""
    
    # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œè€Œä¸æ˜¯è¯»å–é…ç½®æ–‡ä»¶
    if config_path != "data_config.yaml":
        print(f"âš ï¸  è­¦å‘Š: config_pathå‚æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨ç›´æ¥å‚æ•°ä¼ é€’")
    
    # è®¾ç½®é»˜è®¤å€¼
    batch_size = batch_size if batch_size is not None else 8
    num_workers = num_workers if num_workers is not None else 4
    pin_memory = pin_memory if pin_memory is not None else True
    prefetch_factor = prefetch_factor if prefetch_factor is not None else 2
    persistent_workers = persistent_workers if persistent_workers is not None else True
    
    # æ ¹æ®é˜¶æ®µè®¾ç½®é»˜è®¤è¡Œä¸º
    shuffle = shuffle if shuffle is not None else (stage == 'train')
    drop_last = drop_last if drop_last is not None else (stage == 'train')
    
    dataset = Box3DDataset(
        data_root=data_root,
        config_path=config_path,
        stage=stage,
        **kwargs
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=drop_last,
        prefetch_factor=prefetch_factor if num_workers > 0 else None,
        persistent_workers=persistent_workers if num_workers > 0 else False,
        collate_fn=collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰collateå‡½æ•°
    )
    
    return dataloader

def collate_fn(batch):
    """è‡ªå®šä¹‰collateå‡½æ•°ï¼Œä¸segment_dataset.pyä¿æŒä¸€è‡´"""
    # ä½¿ç”¨é»˜è®¤çš„PyTorch collateè¡Œä¸ºï¼Œä½†å¤„ç†å˜é•¿ç‚¹äº‘æ•°æ®
    # å›ºå®šå¤§å°çš„å¼ é‡ä¼šè¢«è‡ªåŠ¨stackï¼Œå˜é•¿çš„ä¿æŒä¸ºåˆ—è¡¨
    
    # åˆ†ç¦»å›ºå®šå¤§å°å’Œå˜é•¿çš„æ•°æ®
    fixed_size_data = {}
    variable_size_data = {}
    
    # å›ºå®šå¤§å°çš„å­—æ®µï¼ˆä¼šè¢«stackï¼‰
    fixed_fields = ['rgb_image', 'x', 'y', 'z', 'w', 'h', 'l', 'rotations']
    # å˜é•¿çš„å­—æ®µï¼ˆä¿æŒä¸ºåˆ—è¡¨ï¼‰
    variable_fields = ['coord', 'grid_coord', 'feat', 'pixel_coords', 'folder_name']
    
    for field in fixed_fields:
        if field in batch[0]:
            fixed_size_data[field] = [sample[field] for sample in batch]
    
    for field in variable_fields:
        if field in batch[0]:
            variable_size_data[field] = [sample[field] for sample in batch]
    
    # ç‰¹æ®Šå¤„ç†offsetå­—æ®µ - éœ€è¦åˆå¹¶æˆç´¯ç§¯åç§»é‡
    offset_data = None
    if 'offset' in batch[0]:
        offsets_list = [sample['offset'] for sample in batch]
        # åˆå¹¶æ‰€æœ‰æ ·æœ¬çš„offsetï¼Œç”Ÿæˆç´¯ç§¯åç§»é‡
        # offset2bincountæœŸæœ›çš„æ ¼å¼ï¼š[cumulative_points]ï¼Œä¸åŒ…å«å¼€å¤´çš„0
        cumulative_offset = []
        current_offset = 0
        for offset in offsets_list:
            # offsetæ˜¯[0, num_points]ï¼Œæˆ‘ä»¬åªéœ€è¦num_points
            num_points = offset[-1].item()
            current_offset += num_points
            cumulative_offset.append(current_offset)
        offset_data = torch.tensor(cumulative_offset, dtype=torch.long)
    
    # å †å å›ºå®šå¤§å°çš„å¼ é‡
    for field, data_list in fixed_size_data.items():
        fixed_size_data[field] = torch.stack(data_list, dim=0)
    
    # åˆå¹¶å˜é•¿çš„å¼ é‡ - å°†æ‰€æœ‰æ ·æœ¬çš„ç‚¹äº‘æ•°æ®é¦–å°¾ç›¸è¿
    for field, data_list in variable_size_data.items():
        if field in ['coord', 'grid_coord', 'feat', 'pixel_coords']:
            variable_size_data[field] = torch.cat(data_list, dim=0)
        else:
            # å¯¹äºéå¼ é‡å­—æ®µï¼Œä¿æŒä¸ºåˆ—è¡¨
            variable_size_data[field] = data_list
    
    # åˆå¹¶ç»“æœ
    result = {**fixed_size_data, **variable_size_data}
    
    # æ·»åŠ å¤„ç†åçš„offsetæ•°æ®
    if offset_data is not None:
        result['offset'] = offset_data
    
    return result

# æµ‹è¯•ä»£ç  - å·²æ›´æ–°ä¸ºä½¿ç”¨ç»Ÿä¸€é…ç½®
if __name__ == "__main__":
    print("âš ï¸  æ³¨æ„ï¼šdataloader_3d.pyçš„æµ‹è¯•ä»£ç å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨train.pyè¿›è¡Œè®­ç»ƒ")
    print("ç°åœ¨æ‰€æœ‰é…ç½®éƒ½é€šè¿‡training_config.yamlç»Ÿä¸€ç®¡ç†")
    
    # ç®€å•æµ‹è¯•ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
    data_root = "sim_data"  # æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´
    
    print("=== åŸºç¡€åŠŸèƒ½æµ‹è¯• ===")
    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
    train_dataset = Box3DDataset(data_root, stage="train")
    
    if len(train_dataset) > 0:
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        sample = train_dataset[0]
        print("\n=== è®­ç»ƒæ ·æœ¬æµ‹è¯• ===")
        print(f"å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        print(f"xåæ ‡: {sample['x'][:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"yåæ ‡: {sample['y'][:5]}...")
        print(f"zåæ ‡: {sample['z'][:5]}...")
        print(f"wå°ºå¯¸: {sample['w'][:5]}...")
        print(f"hå°ºå¯¸: {sample['h'][:5]}...")
        print(f"lå°ºå¯¸: {sample['l'][:5]}...")
        print(f"æ–‡ä»¶å¤¹: {sample['folder_name']}")
        
        print(f"âœ… æ•°æ®é›†å¯ç”¨ï¼ŒåŒ…å« {len(train_dataset)} ä¸ªæ ·æœ¬")
        print(f"ğŸ¨ æ•°æ®å¢å¼ºçŠ¶æ€: {'å¯ç”¨' if train_dataset.augment else 'ç¦ç”¨'}")
        print(f"ğŸ“ æœ€å¤§boxesæ•°é‡: {train_dataset.max_boxes}")
        print(f"ğŸ–¼ï¸ å›¾åƒå°ºå¯¸: {train_dataset.image_size}")
        
    else:
        print("æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„ï¼") 