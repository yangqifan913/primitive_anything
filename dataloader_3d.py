# -*- coding: utf-8 -*-
"""
3D Box Detection DataLoader
åŠ è½½processedæ•°æ®ï¼šRGBXYZå›¾åƒ(npz) + 3D Boxæ ‡æ³¨(json)
"""

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
import yaml
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import random

def load_config(config_path: str = "data_config.yaml") -> Dict:
    """åŠ è½½æ•°æ®é…ç½®æ–‡ä»¶ - å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§é—®é¢˜"""
    print(f"âš ï¸  è­¦å‘Š: load_configå·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨ç»Ÿä¸€é…ç½®æ–‡ä»¶training_config.yaml")
    return {}

class Box3DDataset(Dataset):
    """3D Boxæ£€æµ‹æ•°æ®é›†"""
    
    def __init__(
        self,
        data_root: str,
        config_path: str = "data_config.yaml",  # å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§
        stage: str = "train",  # train, val, test
        # å¿…éœ€å‚æ•°ï¼ˆä»è®­ç»ƒé…ç½®ä¼ å…¥ï¼‰
        max_boxes: Optional[int] = None,
        image_size: Optional[Tuple[int, int]] = None,
        continuous_ranges: Optional[Dict] = None,
        augmentation_config: Optional[Dict] = None,
        # å…¶ä»–å¯é€‰å‚æ•°
        augment: Optional[bool] = None,
        augment_intensity: Optional[float] = None,
        pad_id: Optional[int] = None,
        **kwargs
    ):
        """
        Args:
            data_root: processedæ•°æ®æ ¹ç›®å½•è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§ï¼‰
            stage: è®­ç»ƒé˜¶æ®µ (train/val/test)
            max_boxes: æœ€å¤§boxæ•°é‡
            image_size: å›¾åƒå°ºå¯¸
            continuous_ranges: è¿ç»­å€¼èŒƒå›´é…ç½®
            augmentation_config: æ•°æ®å¢å¼ºé…ç½®
            å…¶ä»–å‚æ•°: å¯é€‰å‚æ•°ä¼šè¦†ç›–é»˜è®¤è®¾ç½®
        """
        self.data_root = Path(data_root)
        self.stage = stage
        
        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œè€Œä¸æ˜¯è¯»å–ä¸å­˜åœ¨çš„é…ç½®æ–‡ä»¶
        if config_path != "data_config.yaml":
            print(f"âš ï¸  è­¦å‘Š: config_pathå‚æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨ç»Ÿä¸€é…ç½®æ–‡ä»¶")
        
        # è®¾ç½®å‚æ•°ï¼ˆä¼˜å…ˆçº§ï¼šç›´æ¥å‚æ•° > é»˜è®¤å€¼ï¼‰
        self.max_boxes = max_boxes if max_boxes is not None else 10
        self.image_size = image_size if image_size is not None else (640, 640)
        self.pad_id = pad_id if pad_id is not None else -1
        
        # ğŸ”§ ä¿®å¤ï¼šæ•°æ®å¢å¼ºè®¾ç½® - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„augmentation_config
        if augmentation_config is not None:
            self.aug_config = augmentation_config
            self.augment = augment if augment is not None else augmentation_config.get('enabled', False)
            base_intensity = augmentation_config.get('intensity', 1.0)
            self.augment_intensity = augment_intensity if augment_intensity is not None else base_intensity
        else:
            # å›é€€åˆ°é»˜è®¤å€¼
            self.aug_config = {}
            self.augment = augment if augment is not None else False
            self.augment_intensity = augment_intensity if augment_intensity is not None else 1.0
        
        # ğŸ”§ ä¿®å¤ï¼šè¿ç»­å€¼èŒƒå›´ - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„continuous_ranges
        if continuous_ranges is not None:
            self.continuous_range_x = continuous_ranges.get('x', [0.5, 2.5])
            self.continuous_range_y = continuous_ranges.get('y', [-2, 2])
            self.continuous_range_z = continuous_ranges.get('z', [-1.5, 1.5])
            self.continuous_range_w = continuous_ranges.get('w', [0.3, 0.7])
            self.continuous_range_h = continuous_ranges.get('h', [0.3, 0.7])
            self.continuous_range_l = continuous_ranges.get('l', [0.3, 0.7])
        else:
            # ä½¿ç”¨é»˜è®¤å€¼
            self.continuous_range_x = [0.5, 2.5]
            self.continuous_range_y = [-2, 2]
            self.continuous_range_z = [-1.5, 1.5]
            self.continuous_range_w = [0.3, 0.7]
            self.continuous_range_h = [0.3, 0.7]
            self.continuous_range_l = [0.3, 0.7]
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        if self.augment:
            print(f"ğŸ¨ æ•°æ®å¢å¼ºå·²å¯ç”¨ (å¼ºåº¦: {self.augment_intensity})")
        else:
            print(f"âŒ æ•°æ®å¢å¼ºå·²ç¦ç”¨")
        
        # æ‰«ææ•°æ®æ–‡ä»¶
        self.samples = self._scan_data()
        
        print(f"Box3DDataset: æ‰¾åˆ° {len(self.samples)} ä¸ªæ ·æœ¬")
        print(f"  æ•°æ®æ ¹ç›®å½•: {self.data_root}")
        print(f"  å›¾åƒå°ºå¯¸: {self.image_size}")
        print(f"  æœ€å¤§boxæ•°: {self.max_boxes}")
        print(f"  æ•°æ®å¢å¼º: {self.augment} (å¼ºåº¦: {self.augment_intensity})")
    
    def _scan_data(self) -> List[Dict]:
        """æ‰«ææ•°æ®ç›®å½•ï¼Œè¿”å›æ ·æœ¬åˆ—è¡¨"""
        samples = []
        
        # æ ¹æ®stageç¡®å®šè¦åŠ è½½çš„æ•°æ®å­ç›®å½•
        if self.stage == "train":
            data_subdir = self.data_root / "train"
        elif self.stage == "val":
            data_subdir = self.data_root / "val"
        elif self.stage == "test":
            data_subdir = self.data_root / "test"
        else:
            # é»˜è®¤åŠ è½½trainæ–‡ä»¶å¤¹
            data_subdir = self.data_root / "train"
            print(f"è­¦å‘Š: æœªçŸ¥çš„stage '{self.stage}'ï¼Œé»˜è®¤åŠ è½½trainæ–‡ä»¶å¤¹")
        
        # æ£€æŸ¥æ•°æ®å­ç›®å½•æ˜¯å¦å­˜åœ¨
        if not data_subdir.exists():
            print(f"é”™è¯¯: æ•°æ®å­ç›®å½•ä¸å­˜åœ¨: {data_subdir}")
            return samples
        
        # éå†æ•°æ®å­ç›®å½•ä¸­çš„æ‰€æœ‰ç¼–å·æ–‡ä»¶å¤¹
        for folder in sorted(data_subdir.iterdir()):
            if not folder.is_dir():
                continue
            
            # æ¥å—çº¯æ•°å­—å’Œå¸¦ä¸‹åˆ’çº¿çš„æ•°å­—æ–‡ä»¶å¤¹å (å¦‚ 0000, 0000_2)
            folder_name = folder.name
            if not (folder_name.isdigit() or (folder_name.replace('_', '').isdigit() and '_' in folder_name)):
                continue
                
            folder_name = folder.name
            npz_file = folder / f"{folder_name}.npz"
            json_file = folder / f"{folder_name}.json"
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if npz_file.exists() and json_file.exists():
                samples.append({
                    'folder_name': folder_name,
                    'npz_file': str(npz_file),
                    'json_file': str(json_file)
                })
            else:
                print(f"è­¦å‘Š: æ–‡ä»¶å¤¹ {folder_name} ç¼ºå°‘å¿…è¦æ–‡ä»¶")
        
        return samples
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def _load_rgbxyz_image(self, npz_file: str) -> np.ndarray:
        """åŠ è½½RGBXYZå›¾åƒæ•°æ®"""
        try:
            data = np.load(npz_file)
            rgbxyz = data['rgbxyz']  # Shape: (H, W, 6) - [R, G, B, X, Y, Z]
            data.close()
            return rgbxyz
        except Exception as e:
            print(f"åŠ è½½å›¾åƒå¤±è´¥ {npz_file}: {e}")
            # è¿”å›ç©ºå›¾åƒ
            return np.zeros((*self.image_size, 6), dtype=np.float32)
    
    def _load_boxes(self, json_file: str) -> List[Dict]:
        """åŠ è½½3D boxæ ‡æ³¨"""
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
            return data.get('boxes', [])
        except Exception as e:
            print(f"åŠ è½½æ ‡æ³¨å¤±è´¥ {json_file}: {e}")
            return []
    
    def _normalize_coordinates(self, boxes: List[Dict]) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """æå–boxåæ ‡å’Œå°ºå¯¸ï¼Œè¿›è¡ŒèŒƒå›´è£å‰ªï¼ŒåŒæ—¶æå–æ—‹è½¬ä¿¡æ¯ï¼ˆä¿æŒåŸå§‹ç‰©ç†æ•°å€¼ï¼Œä¸å½’ä¸€åŒ–ï¼‰"""
        if not boxes:
            # è¿”å›ç©ºæ•°ç»„
            return (np.array([]), np.array([]), np.array([]), 
                   np.array([]), np.array([]), np.array([]), 
                   np.array([]).reshape(0, 4))  # æ—‹è½¬å››å…ƒæ•°
        
        # æå–åæ ‡ã€å°ºå¯¸å’Œæ—‹è½¬
        positions = np.array([box['position'] for box in boxes])  # (N, 3)
        sizes = np.array([box['size'] for box in boxes])  # (N, 3)
        rotations = np.array([box['rotation'] for box in boxes])  # (N, 4) - quaternion [x,y,z,w]
        
        # åˆ†ç¦»xyzåæ ‡å’Œwhlå°ºå¯¸
        x = positions[:, 0]
        y = positions[:, 1] 
        z = positions[:, 2]
        w = sizes[:, 1]  # width
        h = sizes[:, 2]  # height
        l = sizes[:, 0]  # length
        
        # ğŸ”§ ä¿®å¤ï¼šä¸åšå½’ä¸€åŒ–ï¼Œä¿æŒåŸå§‹æ•°å€¼
        # åªè¿›è¡ŒèŒƒå›´æ£€æŸ¥å’Œè£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
        x_clipped = np.clip(x, self.continuous_range_x[0], self.continuous_range_x[1])
        y_clipped = np.clip(y, self.continuous_range_y[0], self.continuous_range_y[1])
        z_clipped = np.clip(z, self.continuous_range_z[0], self.continuous_range_z[1])
        w_clipped = np.clip(w, self.continuous_range_w[0], self.continuous_range_w[1])
        h_clipped = np.clip(h, self.continuous_range_h[0], self.continuous_range_h[1])
        l_clipped = np.clip(l, self.continuous_range_l[0], self.continuous_range_l[1])
        
        return x_clipped, y_clipped, z_clipped, w_clipped, h_clipped, l_clipped, rotations
    
    def _pad_sequences(self, x, y, z, w, h, l, rotations) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """å°†åºåˆ—padåˆ°å›ºå®šé•¿åº¦"""
        current_len = len(x)
        
        if current_len == 0:
            # å¦‚æœæ²¡æœ‰boxï¼Œè¿”å›å…¨paddingçš„tensor
            identity_quat = np.array([0.0, 0.0, 0.0, 1.0])  # å•ä½å››å…ƒæ•° (x,y,z,w)
            return (torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.full((self.max_boxes,), self.pad_id, dtype=torch.float32),
                   torch.from_numpy(np.tile(identity_quat, (self.max_boxes, 1))).float())
        
        if current_len > self.max_boxes:
            # å¦‚æœè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œéšæœºé‡‡æ ·
            indices = np.random.choice(current_len, self.max_boxes, replace=False)
            x = x[indices]
            y = y[indices]
            z = z[indices]
            w = w[indices]
            h = h[indices]
            l = l[indices]
            rotations = rotations[indices]
        else:
            # å¦‚æœä¸è¶³æœ€å¤§é•¿åº¦ï¼Œè¿›è¡Œpadding
            pad_len = self.max_boxes - current_len
            x = np.concatenate([x, np.full(pad_len, self.pad_id)])
            y = np.concatenate([y, np.full(pad_len, self.pad_id)])
            z = np.concatenate([z, np.full(pad_len, self.pad_id)])
            w = np.concatenate([w, np.full(pad_len, self.pad_id)])
            h = np.concatenate([h, np.full(pad_len, self.pad_id)])
            l = np.concatenate([l, np.full(pad_len, self.pad_id)])
            
            # ä¸ºæ—‹è½¬æ•°æ®paddingä½¿ç”¨å•ä½å››å…ƒæ•°
            identity_quat = np.array([0.0, 0.0, 0.0, 1.0])  # å•ä½å››å…ƒæ•° (x,y,z,w)
            pad_rotations = np.tile(identity_quat, (pad_len, 1))
            rotations = np.concatenate([rotations, pad_rotations], axis=0)
        
        return (torch.from_numpy(x).float(),
               torch.from_numpy(y).float(),
               torch.from_numpy(z).float(),
               torch.from_numpy(w).float(),
               torch.from_numpy(h).float(),
               torch.from_numpy(l).float(),
               torch.from_numpy(rotations).float())
    
    def _augment_data(self, rgbxyz: np.ndarray, boxes: List[Dict]) -> Tuple[np.ndarray, List[Dict]]:
        """æ•°æ®å¢å¼º - åŒ…æ‹¬å›¾åƒå™ªç‚¹å’Œç‚¹äº‘å™ªå£°"""
        if not self.augment:
            return rgbxyz, boxes
        
        # æ³¨æ„ï¼šæ•°æ®æ˜¯ä»æ–‡ä»¶æ–°åŠ è½½çš„ï¼Œæ— éœ€å¤åˆ¶
        # ä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œä»ç„¶å¤åˆ¶boxesï¼ˆå› ä¸ºå®ƒä»¬åŒ…å«åµŒå¥—çš„numpyæ•°ç»„ï¼‰
        boxes = [box.copy() for box in boxes]
        for box in boxes:
            box['position'] = box['position'].copy()
            box['size'] = box['size'].copy()
        
        # 2. RGBå›¾åƒå¢å¼º
        rgb_enh = self.aug_config.get('rgb_enhancement', {})
        
        # äº®åº¦è°ƒæ•´
        brightness_cfg = rgb_enh.get('brightness', {})
        if brightness_cfg.get('enabled', True) and random.random() < brightness_cfg.get('probability', 0.7):
            factor_range = brightness_cfg.get('factor_range', [0.8, 1.2])
            brightness_factor = random.uniform(*factor_range)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] * brightness_factor, 0, 255)
        
        # å¯¹æ¯”åº¦è°ƒæ•´
        contrast_cfg = rgb_enh.get('contrast', {})
        if contrast_cfg.get('enabled', True) and random.random() < contrast_cfg.get('probability', 0.7):
            factor_range = contrast_cfg.get('factor_range', [0.8, 1.2])
            contrast_factor = random.uniform(*factor_range)
            mean_rgb = rgbxyz[:, :, :3].mean()
            rgbxyz[:, :, :3] = np.clip((rgbxyz[:, :, :3] - mean_rgb) * contrast_factor + mean_rgb, 0, 255)
        
        # è‰²è°ƒåç§»
        hue_cfg = rgb_enh.get('hue', {})  # ä¿®æ­£é…ç½®é”®å
        if hue_cfg.get('enabled', True) and random.random() < hue_cfg.get('probability', 0.7):
            shift_range = hue_cfg.get('shift_range', [-10, 10])
            hue_shift = random.uniform(*shift_range)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] + hue_shift, 0, 255)
        
        # 3. RGBå›¾åƒå™ªç‚¹
        rgb_noise = self.aug_config.get('rgb_noise', {})
        
        # é«˜æ–¯å™ªå£°
        gaussian_cfg = rgb_noise.get('gaussian', {})
        if gaussian_cfg.get('enabled', True) and random.random() < gaussian_cfg.get('probability', 0.6):
            std_range = gaussian_cfg.get('std_range', [2, 8])
            noise_std = random.uniform(*std_range) * self.augment_intensity
            gaussian_noise = np.random.normal(0, noise_std, rgbxyz[:, :, :3].shape)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] + gaussian_noise, 0, 255)
        
        # æ¤’ç›å™ªå£°
        salt_pepper_cfg = rgb_noise.get('salt_pepper', {})
        if salt_pepper_cfg.get('enabled', True) and random.random() < salt_pepper_cfg.get('probability', 0.4):
            ratio_range = salt_pepper_cfg.get('ratio_range', [0.001, 0.01])
            noise_ratio = random.uniform(*ratio_range) * self.augment_intensity
            mask = np.random.random(rgbxyz[:, :, :3].shape) < noise_ratio
            rgbxyz[:, :, :3][mask] = np.random.choice([0, 255], size=mask.sum())
        
        # æ–‘ç‚¹å™ªå£°
        speckle_cfg = rgb_noise.get('speckle', {})
        if speckle_cfg.get('enabled', True) and random.random() < speckle_cfg.get('probability', 0.3):
            std_range = speckle_cfg.get('std_range', [0.05, 0.15])
            noise_std = random.uniform(*std_range) * self.augment_intensity
            speckle_noise = np.random.normal(0, noise_std, rgbxyz[:, :, :3].shape)
            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] * (1 + speckle_noise), 0, 255)
        

            rgbxyz[:, :, :3] = np.clip(rgbxyz[:, :, :3] * (1 + speckle_noise), 0, 255)
        
        # 4. ç‚¹äº‘(XYZ)å™ªå£°
        pc_config = self.aug_config.get('point_cloud', {})
        
        # XYZåæ ‡é«˜æ–¯å™ªå£°
        gaussian_cfg = pc_config.get('gaussian_noise', {})
        if gaussian_cfg.get('enabled', True) and random.random() < gaussian_cfg.get('probability', 0.7):
            std_ranges = gaussian_cfg.get('std_ranges', {'x': [0.01, 0.05], 'y': [0.01, 0.05], 'z': [0.005, 0.03]})
            xyz_noise_std = [
                random.uniform(*std_ranges.get('x', [0.01, 0.05])) * self.augment_intensity,
                random.uniform(*std_ranges.get('y', [0.01, 0.05])) * self.augment_intensity,
                random.uniform(*std_ranges.get('z', [0.005, 0.03])) * self.augment_intensity
            ]
            
            for i, std in enumerate(xyz_noise_std):
                noise = np.random.normal(0, std, rgbxyz[:, :, 3+i].shape)
                rgbxyz[:, :, 3+i] += noise
        
        # ç‚¹äº‘éšæœºä¸¢å¤±
        dropout_cfg = pc_config.get('dropout', {})
        if dropout_cfg.get('enabled', True) and random.random() < dropout_cfg.get('probability', 0.5):
            ratio_range = dropout_cfg.get('ratio_range', [0.001, 0.01])
            dropout_ratio = random.uniform(*ratio_range) * self.augment_intensity
            dropout_mask = np.random.random(rgbxyz[:, :, 3:6].shape[:2]) < dropout_ratio
            rgbxyz[dropout_mask, 3:6] = 0
        
        # æ·±åº¦é‡åŒ–å™ªå£°
        quant_cfg = pc_config.get('quantization', {})
        if quant_cfg.get('enabled', True) and random.random() < quant_cfg.get('probability', 0.4):
            step_range = quant_cfg.get('step_range', [0.005, 0.02])
            depth_quantization = random.uniform(*step_range) * self.augment_intensity
            # é¿å…é™¤é›¶é”™è¯¯
            if depth_quantization > 0:
                rgbxyz[:, :, 5] = np.round(rgbxyz[:, :, 5] / depth_quantization) * depth_quantization
        
        # ç³»ç»Ÿæ€§åç§»
        bias_cfg = pc_config.get('coordinate_bias', {})
        if bias_cfg.get('enabled', True) and random.random() < bias_cfg.get('probability', 0.3):
            bias_ranges = bias_cfg.get('bias_ranges', {'x': [-0.02, 0.02], 'y': [-0.02, 0.02], 'z': [-0.01, 0.01]})
            xyz_bias = [
                random.uniform(*bias_ranges.get('x', [-0.02, 0.02])) * self.augment_intensity,
                random.uniform(*bias_ranges.get('y', [-0.02, 0.02])) * self.augment_intensity,
                random.uniform(*bias_ranges.get('z', [-0.01, 0.01])) * self.augment_intensity
            ]
            for i, bias in enumerate(xyz_bias):
                rgbxyz[:, :, 3+i] += bias
        
        # 5. 3D Boxæ ‡æ³¨æ‰°åŠ¨
        box_pert = self.aug_config.get('box_augmentation', {})
        if box_pert.get('enabled', True) and random.random() < box_pert.get('probability', 0.2):
            pos_noise_cfg = box_pert.get('position_noise', {})
            size_noise_cfg = box_pert.get('size_noise', {})
            
            for box in boxes:
                # ä½ç½®æ‰°åŠ¨
                if pos_noise_cfg.get('enabled', True):
                    noise_ranges = pos_noise_cfg.get('noise_ranges', {'x': [-0.02, 0.02], 'y': [-0.02, 0.02], 'z': [-0.01, 0.01]})
                    position_noise = [
                        random.uniform(*noise_ranges.get('x', [-0.02, 0.02])),
                        random.uniform(*noise_ranges.get('y', [-0.02, 0.02])),
                        random.uniform(*noise_ranges.get('z', [-0.01, 0.01]))
                    ]
                    for i, noise in enumerate(position_noise):
                        box['position'][i] += noise
                        # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if i == 0:  # X
                            box['position'][i] = np.clip(box['position'][i], 
                                                       self.continuous_range_x[0], 
                                                       self.continuous_range_x[1])
                        elif i == 1:  # Y
                            box['position'][i] = np.clip(box['position'][i], 
                                                       self.continuous_range_y[0], 
                                                       self.continuous_range_y[1])
                        elif i == 2:  # Z
                            box['position'][i] = np.clip(box['position'][i], 
                                                       self.continuous_range_z[0], 
                                                       self.continuous_range_z[1])
                
                # å°ºå¯¸æ‰°åŠ¨
                if size_noise_cfg.get('enabled', True):
                    noise_ranges = size_noise_cfg.get('noise_ranges', {'w': [-0.01, 0.01], 'h': [-0.01, 0.01], 'l': [-0.01, 0.01]})
                    size_noise = [
                        random.uniform(*noise_ranges.get('w', [-0.01, 0.01])),
                        random.uniform(*noise_ranges.get('h', [-0.01, 0.01])),
                        random.uniform(*noise_ranges.get('l', [-0.01, 0.01]))
                    ]
                    for i, noise in enumerate(size_noise):
                        box['size'][i] += noise
                        # ç¡®ä¿å°ºå¯¸ä¸ºæ­£ä¸”åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if i == 0:  # width
                            box['size'][i] = np.clip(box['size'][i], 
                                                    self.continuous_range_w[0], 
                                                    self.continuous_range_w[1])
                        elif i == 1:  # height
                            box['size'][i] = np.clip(box['size'][i], 
                                                    self.continuous_range_h[0], 
                                                    self.continuous_range_h[1])
                        elif i == 2:  # length
                            box['size'][i] = np.clip(box['size'][i], 
                                                    self.continuous_range_l[0], 
                                                    self.continuous_range_l[1])
        
        return rgbxyz, boxes
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """è·å–å•ä¸ªæ ·æœ¬"""
        sample = self.samples[idx]
        
        # åŠ è½½RGBXYZå›¾åƒ
        rgbxyz = self._load_rgbxyz_image(sample['npz_file'])  # (H, W, 6)
        
        # åŠ è½½3D boxæ ‡æ³¨
        boxes = self._load_boxes(sample['json_file'])
        
        # æ•°æ®å¢å¼º
        rgbxyz, boxes = self._augment_data(rgbxyz, boxes)
        
        # å½’ä¸€åŒ–åæ ‡å¹¶æå–æ—‹è½¬ä¿¡æ¯
        x, y, z, w, h, l, rotations = self._normalize_coordinates(boxes)
        
        # Padåºåˆ—åˆ°å›ºå®šé•¿åº¦
        x_padded, y_padded, z_padded, w_padded, h_padded, l_padded, rotations_padded = self._pad_sequences(x, y, z, w, h, l, rotations)
        
        # è½¬æ¢å›¾åƒæ ¼å¼ï¼š(H, W, 6) -> (6, H, W)
        rgbxyz_tensor = torch.from_numpy(rgbxyz).permute(2, 0, 1).float()
        
        # å½’ä¸€åŒ–RGBé€šé“åˆ°[0,1]
        rgbxyz_tensor[:3] = rgbxyz_tensor[:3] / 255.0
        
        # ğŸ”§ ä¿®å¤ï¼šä¸å½’ä¸€åŒ–XYZç‚¹äº‘é€šé“ï¼Œä¿æŒåŸå§‹æ•°å€¼
        # åªè¿›è¡ŒèŒƒå›´è£å‰ªï¼Œç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
        rgbxyz_tensor[3] = torch.clamp(rgbxyz_tensor[3], self.continuous_range_x[0], self.continuous_range_x[1])  # X
        rgbxyz_tensor[4] = torch.clamp(rgbxyz_tensor[4], self.continuous_range_y[0], self.continuous_range_y[1])  # Y  
        rgbxyz_tensor[5] = torch.clamp(rgbxyz_tensor[5], self.continuous_range_z[0], self.continuous_range_z[1])  # Z
        
        return {
            'image': rgbxyz_tensor,  # (6, H, W) - RGBXYZ
            'x': x_padded,          # (max_boxes,)
            'y': y_padded,          # (max_boxes,)
            'z': z_padded,          # (max_boxes,)
            'w': w_padded,          # (max_boxes,)
            'h': h_padded,          # (max_boxes,)
            'l': l_padded,          # (max_boxes,)
            'rotations': rotations_padded,  # (max_boxes, 4) - å››å…ƒæ•°æ—‹è½¬
            'folder_name': sample['folder_name']  # ç”¨äºè°ƒè¯•
        }

def create_dataloader(
    data_root: str,
    config_path: str = "data_config.yaml",  # å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é˜²å…¼å®¹æ€§
    stage: str = "train",
    batch_size: Optional[int] = None,
    shuffle: Optional[bool] = None,
    num_workers: Optional[int] = None,
    pin_memory: Optional[bool] = None,
    prefetch_factor: Optional[int] = None,
    persistent_workers: Optional[bool] = None,
    drop_last: Optional[bool] = None,
    **kwargs
) -> DataLoader:
    """åˆ›å»ºDataLoader - ç°åœ¨ä½¿ç”¨ç›´æ¥å‚æ•°è€Œä¸æ˜¯é…ç½®æ–‡ä»¶"""
    
    # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œè€Œä¸æ˜¯è¯»å–é…ç½®æ–‡ä»¶
    if config_path != "data_config.yaml":
        print(f"âš ï¸  è­¦å‘Š: config_pathå‚æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨ç›´æ¥å‚æ•°ä¼ é€’")
    
    # è®¾ç½®é»˜è®¤å€¼
    batch_size = batch_size if batch_size is not None else 8
    num_workers = num_workers if num_workers is not None else 4
    pin_memory = pin_memory if pin_memory is not None else True
    prefetch_factor = prefetch_factor if prefetch_factor is not None else 2
    persistent_workers = persistent_workers if persistent_workers is not None else True
    
    # æ ¹æ®é˜¶æ®µè®¾ç½®é»˜è®¤è¡Œä¸º
    shuffle = shuffle if shuffle is not None else (stage == 'train')
    drop_last = drop_last if drop_last is not None else (stage == 'train')
    
    dataset = Box3DDataset(
        data_root=data_root,
        config_path=config_path,
        stage=stage,
        **kwargs
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=drop_last,
        prefetch_factor=prefetch_factor if num_workers > 0 else None,
        persistent_workers=persistent_workers if num_workers > 0 else False
    )
    
    return dataloader

# æµ‹è¯•ä»£ç  - å·²æ›´æ–°ä¸ºä½¿ç”¨ç»Ÿä¸€é…ç½®
if __name__ == "__main__":
    print("âš ï¸  æ³¨æ„ï¼šdataloader_3d.pyçš„æµ‹è¯•ä»£ç å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨train.pyè¿›è¡Œè®­ç»ƒ")
    print("ç°åœ¨æ‰€æœ‰é…ç½®éƒ½é€šè¿‡training_config.yamlç»Ÿä¸€ç®¡ç†")
    
    # ç®€å•æµ‹è¯•ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
    data_root = "sim_data"  # æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´
    
    print("=== åŸºç¡€åŠŸèƒ½æµ‹è¯• ===")
    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
    train_dataset = Box3DDataset(data_root, stage="train")
    
    if len(train_dataset) > 0:
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        sample = train_dataset[0]
        print("\n=== è®­ç»ƒæ ·æœ¬æµ‹è¯• ===")
        print(f"å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        print(f"xåæ ‡: {sample['x'][:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"yåæ ‡: {sample['y'][:5]}...")
        print(f"zåæ ‡: {sample['z'][:5]}...")
        print(f"wå°ºå¯¸: {sample['w'][:5]}...")
        print(f"hå°ºå¯¸: {sample['h'][:5]}...")
        print(f"lå°ºå¯¸: {sample['l'][:5]}...")
        print(f"æ–‡ä»¶å¤¹: {sample['folder_name']}")
        
        print(f"âœ… æ•°æ®é›†å¯ç”¨ï¼ŒåŒ…å« {len(train_dataset)} ä¸ªæ ·æœ¬")
        print(f"ğŸ¨ æ•°æ®å¢å¼ºçŠ¶æ€: {'å¯ç”¨' if train_dataset.augment else 'ç¦ç”¨'}")
        print(f"ğŸ“ æœ€å¤§boxesæ•°é‡: {train_dataset.max_boxes}")
        print(f"ğŸ–¼ï¸ å›¾åƒå°ºå¯¸: {train_dataset.image_size}")
        
    else:
        print("æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„ï¼") 