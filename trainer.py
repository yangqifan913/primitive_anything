# -*- coding: utf-8 -*-
"""
åˆ†æ®µå¼3Dæ£€æµ‹è®­ç»ƒå™¨
æ”¯æŒteacher forcing -> scheduled sampling -> pure generationçš„æ¸è¿›è®­ç»ƒ
å¤šGPUã€SwanLabæ—¥å¿—ã€å®Œæ•´éªŒè¯å’Œcheckpointç®¡ç†
"""

import os
import json
import time
import math
import random
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict

import numpy as np
import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
from torch.cuda.amp import autocast, GradScaler

try:
    import swanlab
    SWANLAB_AVAILABLE = True
except ImportError:
    SWANLAB_AVAILABLE = False
    warnings.warn("SwanLab not available. Install with: pip install swanlab")

from config_loader import ConfigLoader
from primitive_anything_3d import PrimitiveTransformer3D
from loss_3d import AdaptivePrimitiveTransformer3DLoss
from dataloader_3d import create_dataloader


@dataclass
class TrainingPhase:
    """è®­ç»ƒé˜¶æ®µé…ç½®"""
    name: str
    epochs: int
    teacher_forcing_ratio: float    # 1.0=å®Œå…¨teacher forcing, 0.0=å®Œå…¨ç”Ÿæˆ
    scheduled_sampling: bool        # æ˜¯å¦ä½¿ç”¨scheduled sampling
    sampling_strategy: str          # linear, exponential, inverse_sigmoid
    description: str


@dataclass
class TrainingStats:
    """è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
    epoch: int
    phase: str
    teacher_forcing_ratio: float
    train_loss: float
    train_classification_loss: float
    train_iou_loss: float
    train_delta_loss: float
    train_mean_iou: float
    val_loss: float
    val_generation_loss: float
    val_mean_iou: float
    val_generation_iou: float
    learning_rate: float
    adaptive_cls_weight: float
    adaptive_delta_weight: float
    epoch_time: float


class AdvancedTrainer:
    """é«˜çº§3Dæ£€æµ‹è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        config_loader: ConfigLoader,
        output_dir: str = "experiments",
        experiment_name: str = "primitive_3d_exp",
        resume_from: Optional[str] = None,
        local_rank: int = 0,
        world_size: int = 1,
        use_swanlab: bool = True,
        validation_samples: List[int] = None  # æŒ‡å®šç”¨äºéªŒè¯å¯è§†åŒ–çš„æ ·æœ¬ç´¢å¼•
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        Args:
            config_loader: é…ç½®åŠ è½½å™¨
            output_dir: è¾“å‡ºç›®å½•
            experiment_name: å®éªŒåç§°
            resume_from: æ¢å¤è®­ç»ƒçš„checkpointè·¯å¾„
            local_rank: æœ¬åœ°GPUæ’å
            world_size: æ€»GPUæ•°é‡
            use_swanlab: æ˜¯å¦ä½¿ç”¨SwanLab
            validation_samples: éªŒè¯å¯è§†åŒ–æ ·æœ¬ç´¢å¼•åˆ—è¡¨
        """
        self.config_loader = config_loader
        self.local_rank = local_rank
        self.world_size = world_size
        
        self.is_main_process = (local_rank == 0)
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        self.output_dir = Path(output_dir) / experiment_name
        self.checkpoint_dir = self.output_dir / "checkpoints"
        self.validation_dir = self.output_dir / "validation_results"
        
        if self.is_main_process:
            self.output_dir.mkdir(parents=True, exist_ok=True)
            self.checkpoint_dir.mkdir(exist_ok=True)
            self.validation_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–è®¾å¤‡
        self.device = torch.device(f'cuda:{local_rank}' if torch.cuda.is_available() else 'cpu')
        torch.cuda.set_device(local_rank)
        
        # åŠ è½½é…ç½®
        self.model_config = config_loader.get_model_config()
        self.training_config = config_loader.get_training_config()
        
        # åˆå§‹åŒ–SwanLab - åªåœ¨ä¸»è¿›ç¨‹åˆå§‹åŒ–
        self.use_swanlab = use_swanlab and SWANLAB_AVAILABLE and self.is_main_process
        if self.use_swanlab:
            if self.is_main_process:
                print(f"ğŸ“Š åˆå§‹åŒ–SwanLabæ—¥å¿—...")
            swanlab.init(
                project="primitive-3d-detection",
                experiment_name=experiment_name,
                description="3Dç‰©ä½“æ£€æµ‹withåˆ†æ®µå¼è®­ç»ƒ",
                config=dict(
                    model_config=self.model_config,
                    training_config=self.training_config
                )
            )
            if self.is_main_process:
                print(f"âœ… SwanLabåˆå§‹åŒ–å®Œæˆ")
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½è®­ç»ƒé˜¶æ®µ
        phases_config = config_loader.get_training_phases()
        self.training_phases = []
        
        for phase_name, phase_config in phases_config.items():
            self.training_phases.append(TrainingPhase(
                name=phase_name,
                epochs=phase_config.get('epochs', 15),
                teacher_forcing_ratio=phase_config.get('teacher_forcing_ratio', 1.0),
                scheduled_sampling=phase_config.get('scheduled_sampling', False),
                sampling_strategy=phase_config.get('sampling_strategy', "none"),
                description=phase_config.get('description', f"{phase_name}é˜¶æ®µ")
            ))
        
        # éªŒè¯æ ·æœ¬ç´¢å¼•
        global_config = self.config_loader.get_global_config()
        self.validation_samples = validation_samples or global_config['logging']['validation_samples']
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.current_phase_idx = 0
        self.best_val_loss = float('inf')
        self.best_generation_loss = float('inf')
        self.training_stats = []
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.use_amp = self.training_config.get('mixed_precision', True)
        if self.use_amp:
            try:
                # ä½¿ç”¨æ–°çš„APIï¼ˆPyTorch 2.0+ï¼‰
                self.scaler = torch.amp.GradScaler('cuda')
            except TypeError:
                # å›é€€åˆ°æ—§API
                self.scaler = GradScaler()
        else:
            self.scaler = None
        
        # è®­ç»ƒä¼˜åŒ–é…ç½®
        opt_config = self.training_config.get('optimizations', {})
        
        # æå‰åœæ­¢é…ç½®
        early_stop_config = opt_config.get('early_stopping', {})
        self.enable_early_stopping = early_stop_config.get('enabled', True)
        self.eos_threshold = early_stop_config.get('eos_threshold', 0.5)
        self.adaptive_sequence_length = early_stop_config.get('adaptive_sequence_length', True)
        
        # å¢é‡æ¨ç†é…ç½®
        inference_config = opt_config.get('incremental_inference', {})
        self.use_incremental_inference = inference_config.get('enabled', True)
        self.incremental_temperature = inference_config.get('temperature', 1.0)
        
        # æ¢¯åº¦è£å‰ªé…ç½®
        grad_clip_config = opt_config.get('gradient_clipping', {})
        self.use_grad_clipping = grad_clip_config.get('enabled', True)
        self.max_grad_norm = grad_clip_config.get('max_norm', 1.0)
        
        # PyTorchç¼–è¯‘ä¼˜åŒ–é…ç½®
        self.torch_compile_config = opt_config.get('torch_compile', {})
        
        # CuDNNä¼˜åŒ–é…ç½®
        cudnn_config = opt_config.get('cudnn_optimizations', {})
        if cudnn_config.get('benchmark', True):
            torch.backends.cudnn.benchmark = True
        if not cudnn_config.get('deterministic', True):
            torch.backends.cudnn.deterministic = False
        
        # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œæ•°æ®åŠ è½½å™¨
        self._setup_model_and_data()
        
        # æ¢å¤è®­ç»ƒçŠ¶æ€
        if resume_from:
            self._load_checkpoint(resume_from)
        
        if self.is_main_process:
            print(f"âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ (Rank {local_rank}/{world_size})")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
            print(f"ğŸ¯ è®­ç»ƒé˜¶æ®µ: {len(self.training_phases)}ä¸ªé˜¶æ®µ")
            print(f"ğŸ“Š SwanLabæ—¥å¿—: {'å¯ç”¨' if self.use_swanlab else 'ç¦ç”¨'}")
            print(f"ğŸ–¥ï¸  GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"ğŸš€ åˆ†å¸ƒå¼è®­ç»ƒ: {'å¯ç”¨' if (self.world_size > 1 and torch.cuda.device_count() > 1) else 'ç¦ç”¨'}")
        else:
            print(f"ğŸ”„ å·¥ä½œè¿›ç¨‹å¯åŠ¨ (Rank {local_rank}/{world_size})")
            print(f"   GPUè®¾å¤‡: {self.device}")
            print(f"   ç­‰å¾…ä¸»è¿›ç¨‹åŒæ­¥...")
        
        # å¤šGPUåŒæ­¥ç‚¹
        if self.world_size > 1 and torch.cuda.device_count() > 1:
            if torch.distributed.is_initialized():
                torch.distributed.barrier()
                if self.is_main_process:
                    print(f"âœ… æ‰€æœ‰è¿›ç¨‹åŒæ­¥å®Œæˆï¼Œå¼€å§‹è®­ç»ƒ...")
    
    def _setup_model_and_data(self):
        """è®¾ç½®æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œæ•°æ®åŠ è½½å™¨"""
        # åˆ›å»ºæ¨¡å‹
        model_config = self.config_loader.get_model_config()
        global_config = self.config_loader.get_global_config()
        
        # è·å–æ•°æ®é…ç½®ç”¨äºè¿ç»­èŒƒå›´
        data_config = self.config_loader.get_data_config()
        continuous_ranges = data_config.get('continuous_ranges', {})
        
        # ä»æ¨¡å‹é…ç½®ä¸­è·å–å„ä¸ªéƒ¨åˆ†
        discretization = model_config.get('discretization', {})
        embeddings = model_config.get('embeddings', {})
        transformer = model_config.get('transformer', {})
        image_encoder = model_config.get('image_encoder', {})
        conditioning = model_config.get('conditioning', {})
        advanced = model_config.get('advanced', {})
        
        # éªŒè¯å¿…è¦çš„é…ç½®éƒ¨åˆ†æ˜¯å¦å­˜åœ¨
        if not discretization:
            raise ValueError("æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘ 'discretization' éƒ¨åˆ†")
        if not embeddings:
            raise ValueError("æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘ 'embeddings' éƒ¨åˆ†")
        if not transformer:
            raise ValueError("æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘ 'transformer' éƒ¨åˆ†")
        if not image_encoder:
            raise ValueError("æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘ 'image_encoder' éƒ¨åˆ†")
        if not conditioning:
            raise ValueError("æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘ 'conditioning' éƒ¨åˆ†")
        if not advanced:
            raise ValueError("æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘ 'advanced' éƒ¨åˆ†")
        
        self.model = PrimitiveTransformer3D(
            # ç¦»æ•£åŒ–å‚æ•°
            num_discrete_x=discretization['num_discrete_x'],
            num_discrete_y=discretization['num_discrete_y'],
            num_discrete_z=discretization['num_discrete_z'],
            num_discrete_w=discretization['num_discrete_w'],
            num_discrete_h=discretization['num_discrete_h'],
            num_discrete_l=discretization['num_discrete_l'],
            
            # è¿ç»­èŒƒå›´
            continuous_range_x=continuous_ranges['x'],
            continuous_range_y=continuous_ranges['y'],
            continuous_range_z=continuous_ranges['z'],
            continuous_range_w=continuous_ranges['w'],
            continuous_range_h=continuous_ranges['h'],
            continuous_range_l=continuous_ranges['l'],
            
            # åµŒå…¥ç»´åº¦
            dim_x_embed=embeddings['dim_x_embed'],
            dim_y_embed=embeddings['dim_y_embed'],
            dim_z_embed=embeddings['dim_z_embed'],
            dim_w_embed=embeddings['dim_w_embed'],
            dim_h_embed=embeddings['dim_h_embed'],
            dim_l_embed=embeddings['dim_l_embed'],
            
            # æ¨¡å‹å‚æ•°
            max_primitive_len=global_config['max_seq_len'],
            dim=transformer['dim'],
            attn_depth=transformer['depth'],
            attn_heads=transformer['heads'],
            attn_dim_head=transformer['dim_head'],
            attn_dropout=transformer['attn_dropout'],  # æ³¨æ„åŠ›dropout
            ff_dropout=transformer['ff_dropout'],      # å‰é¦ˆdropout
            
            # å›¾åƒç¼–ç å™¨å‚æ•°
            image_encoder_dim=image_encoder['output_dim'],
            use_fpn=image_encoder['use_fpn'],
            backbone=image_encoder['backbone'],
            pretrained=image_encoder['pretrained'],
            
            # æ¡ä»¶åŒ–é…ç½®
            condition_on_image=conditioning['condition_on_image'],
            gateloop_use_heinsen=advanced['gateloop_use_heinsen'],
            
            # å…¶ä»–å‚æ•°
            pad_id=global_config['pad_id']
        )
        self.model = self.model.to(self.device)
        
        # PyTorch 2.0 ç¼–è¯‘ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(torch, 'compile') and self.torch_compile_config.get('enabled', False):
            compile_mode = self.torch_compile_config.get('mode', 'default')
            if self.is_main_process:
                print(f"ğŸ”¥ å¯ç”¨PyTorch 2.0ç¼–è¯‘ä¼˜åŒ– (mode: {compile_mode})")
            self.model = torch.compile(self.model, mode=compile_mode)
        
        # å¤šGPUè®¾ç½® - åªæœ‰åœ¨çœŸæ­£çš„å¤šGPUç¯å¢ƒä¸‹æ‰å¯ç”¨DDP
        if self.world_size > 1 and torch.cuda.device_count() > 1:
            if self.is_main_process:
                print(f"ğŸš€ å¯ç”¨åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ (DDP)")
            # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            self.model = self.model.to(self.device)
            # ä½¿ç”¨DDPåŒ…è£…æ¨¡å‹
            self.model = DDP(self.model, device_ids=[self.local_rank], output_device=self.local_rank)
            if self.is_main_process:
                print(f"âœ… DDPæ¨¡å‹åŒ…è£…å®Œæˆ")
        elif self.world_size > 1 and self.is_main_process:
            print(f"âš ï¸  æ£€æµ‹åˆ°å•GPUç¯å¢ƒï¼Œç¦ç”¨DDP")
        else:
            # å•GPUæˆ–world_size=1çš„æƒ…å†µ
            if self.is_main_process:
                print(f"ğŸ–¥ï¸  å•GPUè®­ç»ƒæ¨¡å¼")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ç§»é™¤ç¡¬ç¼–ç 
        data_config = self.config_loader.get_data_config()
        global_config = self.config_loader.get_global_config()
        dataset_config = data_config['dataset']
        dataloader_config = data_config['dataloader']
        
        # è°ƒè¯•ä¿¡æ¯
        if self.is_main_process:
            print(f"ğŸ” æ•°æ®åŠ è½½å™¨é…ç½®:")
            print(f"   åŸå§‹batch_size: {dataloader_config.get('batch_size', 'N/A')}")
            print(f"   world_size: {self.world_size}")
            print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"   æ•°æ®é›†è·¯å¾„: {dataset_config.get('data_root', 'N/A')}")
        
        # å…ˆåˆ›å»ºæ•°æ®é›†
        from dataloader_3d import Box3DDataset
        
        # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä¼ é€’é…ç½®å‚æ•°ï¼Œä¸ä¾èµ–å¤–éƒ¨é…ç½®æ–‡ä»¶
        train_dataset = Box3DDataset(
            data_root=dataset_config['data_root'],
            stage="train",
            max_boxes=global_config['max_seq_len'],
            image_size=global_config['image_size'],
            continuous_ranges=data_config['continuous_ranges'],
            augmentation_config=data_config['augmentation']
        )
        
        val_dataset = Box3DDataset(
            data_root=dataset_config['data_root'],
            stage="val",
            max_boxes=global_config['max_seq_len'],
            image_size=global_config['image_size'],
            continuous_ranges=data_config['continuous_ranges'],
            augmentation_config={}  # éªŒè¯æ—¶ä¸ä½¿ç”¨æ•°æ®å¢å¼º
        )
        
        # åˆ†å¸ƒå¼é‡‡æ ·å™¨ - åªæœ‰åœ¨çœŸæ­£çš„å¤šGPUç¯å¢ƒä¸‹æ‰åˆ›å»º
        if self.world_size > 1 and torch.cuda.device_count() > 1:
            if self.is_main_process:
                print(f"ğŸš€ å¯ç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨")
            self.train_sampler = DistributedSampler(train_dataset)
            self.val_sampler = DistributedSampler(val_dataset, shuffle=False)
            if self.is_main_process:
                print(f"âœ… åˆ†å¸ƒå¼é‡‡æ ·å™¨åˆ›å»ºå®Œæˆ")
        else:
            if self.world_size > 1 and self.is_main_process:
                print(f"âš ï¸  æ£€æµ‹åˆ°å•GPUç¯å¢ƒï¼Œç¦ç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨")
            self.train_sampler = None
            self.val_sampler = None
            if self.is_main_process:
                print(f"ğŸ–¥ï¸  ä½¿ç”¨æ™®é€šæ•°æ®åŠ è½½å™¨")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        from torch.utils.data import DataLoader
        
        # å¤šGPUæ—¶è°ƒæ•´batch_size
        original_batch_size = dataloader_config['batch_size']
        effective_batch_size = original_batch_size
        
        if self.world_size > 1 and torch.cuda.device_count() > 1:
            # è®¡ç®—æ¯GPUçš„batch_size
            effective_batch_size = max(1, original_batch_size // self.world_size)
            
            # å¦‚æœæ¯GPUçš„batch_sizeå¤ªå°ï¼Œè‡ªåŠ¨è°ƒæ•´æ€»batch_size
            if effective_batch_size < 1:
                effective_batch_size = 1
                adjusted_total_batch_size = self.world_size
                if self.is_main_process:
                    print(f"âš ï¸  åŸå§‹batch_size={original_batch_size}è¿‡å°ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸ºæ€»batch_size={adjusted_total_batch_size}")
            else:
                adjusted_total_batch_size = original_batch_size
            
            if self.is_main_process:
                print(f"ğŸ“Š å¤šGPUè®­ç»ƒ: æ€»batch_size={adjusted_total_batch_size}, æ¯GPU={effective_batch_size}")
        else:
            if self.is_main_process:
                print(f"ğŸ“Š å•GPUè®­ç»ƒ: batch_size={effective_batch_size}")
        
        # æœ€ç»ˆéªŒè¯
        if effective_batch_size < 1:
            print(f"âŒ é”™è¯¯: batch_size={effective_batch_size}ï¼Œå¼ºåˆ¶è®¾ç½®ä¸º1")
            effective_batch_size = 1
        
        self.train_loader = DataLoader(
            train_dataset,
            batch_size=effective_batch_size,
            sampler=self.train_sampler,
            shuffle=(self.train_sampler is None),  # å¦‚æœæ²¡æœ‰é‡‡æ ·å™¨åˆ™shuffle
            num_workers=dataloader_config['num_workers'],
            pin_memory=dataloader_config['pin_memory'],
            drop_last=True,
            prefetch_factor=dataloader_config['prefetch_factor'] if dataloader_config['num_workers'] > 0 else None,
            persistent_workers=dataloader_config['persistent_workers'] if dataloader_config['num_workers'] > 0 else False
        )
        
        self.val_loader = DataLoader(
            val_dataset,
            batch_size=effective_batch_size,
            sampler=self.val_sampler,
            shuffle=False,
            num_workers=dataloader_config['num_workers'],
            pin_memory=dataloader_config['pin_memory'],
            drop_last=False,
            prefetch_factor=dataloader_config['prefetch_factor'] if dataloader_config['num_workers'] > 0 else None,
            persistent_workers=dataloader_config['persistent_workers'] if dataloader_config['num_workers'] > 0 else False
        )
        
        # ä¼˜åŒ–å™¨ - ç§»é™¤ç¡¬ç¼–ç 
        optimizer_config = self.training_config['optimizer']
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=optimizer_config['lr'],
            weight_decay=optimizer_config['weight_decay'],
            betas=optimizer_config['betas']
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ”¯æŒå¤šç§è°ƒåº¦å™¨ç±»å‹
        scheduler_config = self.training_config['scheduler']
        if scheduler_config['type'] == 'CosineAnnealingLR':
            total_epochs = sum(phase.epochs for phase in self.training_phases)
            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=scheduler_config['T_max'],
                eta_min=scheduler_config['eta_min']
            )
        elif scheduler_config['type'] == 'CosineAnnealingWarmRestarts':
            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
                self.optimizer,
                T_0=scheduler_config['T_0'],
                T_mult=scheduler_config.get('T_mult', 2),
                eta_min=scheduler_config['eta_min']
            )
        else:
            self.scheduler = None
    
    def _compute_teacher_forcing_ratio(self, phase: TrainingPhase, epoch_in_phase: int) -> float:
        """è®¡ç®—å½“å‰çš„teacher forcingæ¯”ä¾‹"""
        if not phase.scheduled_sampling:
            return phase.teacher_forcing_ratio
        
        # Scheduled samplingç­–ç•¥
        progress = epoch_in_phase / phase.epochs
        
        if phase.sampling_strategy == "linear":
            # çº¿æ€§è¡°å‡
            return phase.teacher_forcing_ratio * (1 - progress)
        elif phase.sampling_strategy == "exponential":
            # æŒ‡æ•°è¡°å‡
            return phase.teacher_forcing_ratio * (0.5 ** (progress * 5))
        elif phase.sampling_strategy == "inverse_sigmoid":
            # åsigmoidè¡°å‡ï¼šä»1.0å¹³æ»‘è¡°å‡åˆ°æ¥è¿‘0
            k = 5  # æ§åˆ¶è¡°å‡é€Ÿåº¦
            # è°ƒæ•´å…¬å¼ç¡®ä¿ä»1.0å¼€å§‹è¡°å‡
            sigmoid_factor = 1 / (1 + math.exp(-k * (progress - 0.5)))
            return phase.teacher_forcing_ratio * (1 - sigmoid_factor)
        else:
            return phase.teacher_forcing_ratio
    
    def _create_loss_function(self, phase_name: str):
        """ä¸ºä¸åŒè®­ç»ƒé˜¶æ®µåˆ›å»ºæŸå¤±å‡½æ•°"""
        # æ ¹æ®è®­ç»ƒé˜¶æ®µæ˜ å°„åˆ°é…ç½®ä¸­çš„stage
        stage_mapping = {
            "teacher_forcing": "warmup",
            "scheduled_sampling": "main", 
            "pure_generation": "finetune"
        }
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        loss_config = self.config_loader.get_loss_config()
        global_config = self.config_loader.get_global_config()
        data_config = self.config_loader.get_data_config()
        model_config = self.config_loader.get_model_config()
        
        # ç§»é™¤ç¡¬ç¼–ç ï¼Œå¼ºåˆ¶ä»é…ç½®è¯»å–
        base_weights = loss_config['base_weights']
        adaptive_weights = loss_config['adaptive_weights']
        continuous_ranges = data_config['continuous_ranges']
        discretization = model_config['discretization']
        algorithm_config = loss_config['algorithm']
        data_processing = loss_config['data_processing']
        
        return AdaptivePrimitiveTransformer3DLoss(
            # ç¦»æ•£åŒ–å‚æ•°
            num_discrete_x=discretization['num_discrete_x'],
            num_discrete_y=discretization['num_discrete_y'],
            num_discrete_z=discretization['num_discrete_z'],
            num_discrete_w=discretization['num_discrete_w'],
            num_discrete_h=discretization['num_discrete_h'],
            num_discrete_l=discretization['num_discrete_l'],
            
            # è¿ç»­èŒƒå›´å‚æ•°
            continuous_range_x=tuple(continuous_ranges['x']),
            continuous_range_y=tuple(continuous_ranges['y']),
            continuous_range_z=tuple(continuous_ranges['z']),
            continuous_range_w=tuple(continuous_ranges['w']),
            continuous_range_h=tuple(continuous_ranges['h']),
            continuous_range_l=tuple(continuous_ranges['l']),
            
            # åŸºç¡€æŸå¤±æƒé‡
            base_classification_weight=base_weights['classification'],
            iou_weight=base_weights['iou'],
            delta_weight=base_weights['delta'],
            eos_weight=base_weights['eos'],
            
            # è‡ªé€‚åº”æƒé‡å‚æ•°
            adaptive_classification=adaptive_weights['adaptive_classification'],
            adaptive_delta=adaptive_weights['adaptive_delta'],
            min_classification_weight=adaptive_weights['classification_range']['min'],
            max_classification_weight=adaptive_weights['classification_range']['max'],
            min_delta_weight=adaptive_weights['delta_range']['min'],
            max_delta_weight=adaptive_weights['delta_range']['max'],
            iou_threshold_high=adaptive_weights['thresholds']['high'],
            iou_threshold_low=adaptive_weights['thresholds']['low'],
            
            # æ•°æ®å¤„ç†å‚æ•°
            pad_id=data_processing['pad_id'],
            label_smoothing=data_processing['label_smoothing'],
            
            # ç®—æ³•å‚æ•°
            distance_aware_cls=algorithm_config['distance_aware']['enabled'],
            distance_alpha=algorithm_config['distance_aware']['alpha'],
            focal_gamma=algorithm_config['focal']['gamma']
        )
    
    def _forward_with_sampling_strategy(self, batch: Dict, teacher_forcing_ratio: float) -> Dict:
        """æ ¹æ®é‡‡æ ·ç­–ç•¥è¿›è¡Œå‰å‘ä¼ æ’­
        
        Args:
            batch: è¾“å…¥batchæ•°æ®
            teacher_forcing_ratio: é‡‡æ ·æ¯”ä¾‹
                - 1.0: çº¯Teacher Forcing (100% GT)
                - 0.0~1.0: Scheduled Sampling (éƒ¨åˆ†GT + éƒ¨åˆ†é¢„æµ‹)
                - 0.0: çº¯Generation (100% é¢„æµ‹)
        """
        rgbxyz = batch['image'].to(self.device)  # [B, 6, H, W]
        targets = {
            'x': batch['x'].to(self.device),
            'y': batch['y'].to(self.device),
            'z': batch['z'].to(self.device),
            'w': batch['w'].to(self.device),
            'h': batch['h'].to(self.device),
            'l': batch['l'].to(self.device),
        }
        
        # è·å–æ¨¡å‹
        if hasattr(self.model, 'module'):
            model = self.model.module
        else:
            model = self.model
        
        # æ ¹æ®teacher_forcing_ratioé€‰æ‹©ä¸åŒçš„ç­–ç•¥
        if teacher_forcing_ratio >= 1.0:
            # å®Œå…¨teacher forcingï¼šç›´æ¥ç”¨GT
            inputs = targets
            # ç»Ÿä¸€ä½¿ç”¨forward_with_predictions
            outputs = model.forward_with_predictions(
                x=inputs['x'],
                y=inputs['y'],
                z=inputs['z'],
                w=inputs['w'],
                h=inputs['h'],
                l=inputs['l'],
                image=rgbxyz
            )
            return outputs
        elif teacher_forcing_ratio == 0.0:
            return self._forward_with_pure_generation(rgbxyz, targets, model)
        else:
            return self._forward_with_scheduled_sampling(rgbxyz, targets, teacher_forcing_ratio, model)
        
        
    
    def _forward_with_scheduled_sampling(self, rgbxyz: torch.Tensor, targets: Dict, teacher_forcing_ratio: float, model) -> Dict:
        """Scheduled Samplingå®ç° - æ”¯æŒæ¢¯åº¦ä¼ æ’­"""
        batch_size = rgbxyz.size(0)
        seq_len = targets['x'].size(1)
        device = rgbxyz.device
        
        # ===== ä½¿ç”¨æ”¯æŒæ¢¯åº¦çš„å¢é‡ç”Ÿæˆè·å–é¢„æµ‹åºåˆ— =====
        # ç”Ÿæˆå®Œæ•´çš„é¢„æµ‹åºåˆ—ï¼ˆä¿æŒæ¢¯åº¦ï¼‰
        predicted_output = self._forward_with_gradient_preserving_generation(
            model, rgbxyz, targets, seq_len, device
        )
        
        # ä»é¢„æµ‹è¾“å‡ºä¸­æå–è¿ç»­å€¼
        continuous_predictions = predicted_output['continuous_dict']
        
        # è®¡ç®—åºåˆ—é•¿åº¦å’Œåˆ›å»ºmask
        sequence_lengths = self._compute_sequence_lengths(targets)
        
        # æ„å»ºæ··åˆè¾“å…¥åºåˆ—ï¼ˆä¿æŒæ¢¯åº¦ï¼‰
        mixed_inputs = {}
        for attr in ['x', 'y', 'z', 'w', 'h', 'l']:
            continuous_pred = continuous_predictions[f'{attr}_continuous']  # [B, seq_len]
            # ç¡®ä¿ç»´åº¦åŒ¹é…GT
            target_seq_len = targets[attr].shape[1]
            if continuous_pred.shape[1] > target_seq_len:
                continuous_pred = continuous_pred[:, :target_seq_len]
            elif continuous_pred.shape[1] < target_seq_len:
                # å¡«å……åˆ°ç›®æ ‡é•¿åº¦
                padding = torch.zeros(
                    continuous_pred.shape[0], 
                    target_seq_len - continuous_pred.shape[1], 
                    device=device,
                    requires_grad=True
                )
                continuous_pred = torch.cat([continuous_pred, padding], dim=1)
            
            # åˆå§‹åŒ–æ··åˆè¾“å…¥
            mixed_inputs[attr] = targets[attr].clone().float()  # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
            
            # åªåœ¨æœ‰æ•ˆä½ç½®è¿›è¡Œteacher forcing vs é¢„æµ‹çš„é€‰æ‹©
            for b in range(batch_size):
                seq_len_b = sequence_lengths[b].item()
                if seq_len_b > 0:
                    # åœ¨æœ‰æ•ˆä½ç½®éšæœºé€‰æ‹©ä½¿ç”¨GTè¿˜æ˜¯é¢„æµ‹
                    use_gt = torch.rand(seq_len_b, device=device) < teacher_forcing_ratio
                    
                    # åˆ›å»ºæ–°çš„åºåˆ—è€Œä¸æ˜¯åŸåœ°ä¿®æ”¹
                    new_sequence = mixed_inputs[attr][b].clone()
                    for pos in range(seq_len_b):
                        if use_gt[pos]:
                            new_sequence[pos] = targets[attr][b, pos]
                        else:
                            new_sequence[pos] = continuous_pred[b, pos]
                    # ä½¿ç”¨catæ“ä½œæ¥é¿å…åŸåœ°ä¿®æ”¹
                    mixed_inputs[attr] = torch.cat([
                        mixed_inputs[attr][:b],
                        new_sequence.unsqueeze(0),
                        mixed_inputs[attr][b+1:]
                    ], dim=0)
        
        # ===== ä½¿ç”¨æ··åˆåºåˆ—è¿›è¡Œå‰å‘ä¼ æ’­ï¼ˆä¿æŒæ¢¯åº¦ï¼‰ =====
        return model.forward_with_predictions(
            x=mixed_inputs['x'],
            y=mixed_inputs['y'],
            z=mixed_inputs['z'],
            w=mixed_inputs['w'],
            h=mixed_inputs['h'],
            l=mixed_inputs['l'],
            image=rgbxyz
        )
    

    def _forward_with_pure_generation(self, rgbxyz: torch.Tensor, targets: Dict, model) -> Dict:
        """Pure Generationè®­ç»ƒ - æ”¯æŒæ¢¯åº¦ä¼ æ’­çš„å¢é‡ç”Ÿæˆ"""
        batch_size = rgbxyz.size(0)
        seq_len = targets['x'].size(1)
        device = rgbxyz.device
        
        # ===== ä½¿ç”¨æ”¯æŒæ¢¯åº¦çš„å¢é‡ç”Ÿæˆ =====
        return self._forward_with_gradient_preserving_generation(
            model, rgbxyz, targets, seq_len, device
        )
    

    def _forward_with_gradient_preserving_generation(self, model, rgbxyz: torch.Tensor, targets: Dict, seq_len: int, device: torch.device) -> Dict:
        """
        æ”¯æŒæ¢¯åº¦çš„å¢é‡ç”Ÿæˆ - ä½¿ç”¨çœŸæ­£çš„å¢é‡è§£ç 
        
        è¿™ä¸ªç‰ˆæœ¬ä½¿ç”¨ç±»ä¼¼ generate_next_box_incremental çš„é€»è¾‘ï¼Œä½†ä¿æŒæ¢¯åº¦æµåŠ¨
        """
        batch_size = rgbxyz.size(0)
        
        # 1. ç¼–ç å›¾åƒï¼ˆåªè®¡ç®—ä¸€æ¬¡ï¼‰
        image_embed = model.image_encoder(rgbxyz)
        
        # ğŸ”§ ä¿®å¤Bugï¼šæ·»åŠ 2Dä½ç½®ç¼–ç ï¼ˆä¸æ¨ç†ä»£ç ä¿æŒä¸€è‡´ï¼‰
        H = W = int(np.sqrt(image_embed.shape[1]))
        if H * W == image_embed.shape[1]:
            from primitive_anything_3d import build_2d_sine_positional_encoding
            pos_embed_2d = build_2d_sine_positional_encoding(H, W, image_embed.shape[-1])
            pos_embed_2d = pos_embed_2d.flatten(0, 1).unsqueeze(0).to(image_embed.device)
            image_embed = image_embed + pos_embed_2d
        
        image_cond = None
        if model.condition_on_image and model.image_film_cond is not None:
            pooled_image_embed = image_embed.mean(dim=1)
            image_cond = model.image_cond_proj_film(pooled_image_embed)
        
        # 2. åˆå§‹åŒ–åºåˆ—çŠ¶æ€
        from einops import repeat
        current_sequence = repeat(model.sos_token, 'n d -> b n d', b=batch_size)
        
        # 3. åˆå§‹åŒ–ç¼“å­˜ï¼ˆç”¨äºçœŸæ­£çš„å¢é‡è§£ç ï¼‰
        decoder_cache = None
        gateloop_cache = []
        
        # å­˜å‚¨æ¯ä¸€æ­¥çš„è¾“å‡º
        all_logits = {f'{attr}_logits': [] for attr in ['x', 'y', 'z', 'w', 'h', 'l']}
        all_deltas = {f'{attr}_delta': [] for attr in ['x', 'y', 'z', 'w', 'h', 'l']}
        all_continuous = {f'{attr}_continuous': [] for attr in ['x', 'y', 'z', 'w', 'h', 'l']}
        all_eos_logits = []
        
        # 4. é€æ­¥ç”Ÿæˆï¼Œä½¿ç”¨çœŸæ­£çš„å¢é‡è§£ç 
        for step in range(seq_len):
            current_len = current_sequence.shape[1]
            if step == 0:
                # ç¬¬ä¸€æ­¥ï¼šå®Œæ•´å‰å‘ä¼ æ’­ï¼Œåˆå§‹åŒ–ç¼“å­˜
                primitive_codes = current_sequence
                
                # æ·»åŠ ä½ç½®ç¼–ç 
                pos_embed = model.pos_embed[:, :current_len, :]
                primitive_codes = primitive_codes + pos_embed
                
                # å›¾åƒæ¡ä»¶åŒ–
                if image_cond is not None:
                    primitive_codes = model.image_film_cond(primitive_codes, image_cond)
                
                # é—¨æ§å¾ªç¯å—ï¼ˆåˆå§‹åŒ–ç¼“å­˜ï¼‰
                if model.gateloop_block is not None:
                    primitive_codes, gateloop_cache = model.gateloop_block(primitive_codes, cache=None)
                
                # Transformerè§£ç ï¼ˆåˆå§‹åŒ–decoderç¼“å­˜ï¼‰
                attended_codes, decoder_cache = model.decoder(
                    primitive_codes,
                    context=image_embed,
                    cache=None,
                    return_hiddens=True
                )
            else:
                # åç»­æ­¥éª¤ï¼šåªå¤„ç†æ–°tokenï¼ˆçœŸæ­£çš„å¢é‡ï¼ï¼‰
                new_token = current_sequence[:, -1:, :]  # åªæœ‰æœ€æ–°çš„token
                
                # æ·»åŠ ä½ç½®ç¼–ç ï¼ˆåªå¯¹æ–°tokenï¼‰
                pos_embed = model.pos_embed[:, current_len-1:current_len, :]
                primitive_codes = new_token + pos_embed
                
                # å›¾åƒæ¡ä»¶åŒ–ï¼ˆåªå¯¹æ–°tokenï¼‰
                if image_cond is not None:
                    primitive_codes = model.image_film_cond(primitive_codes, image_cond)
                
                # é—¨æ§å¾ªç¯å—å¢é‡è®¡ç®—
                if model.gateloop_block is not None:
                    primitive_codes, gateloop_cache = model.gateloop_block(
                        primitive_codes, 
                        cache=gateloop_cache
                    )
                
                # çœŸæ­£çš„å¢é‡Transformerè§£ç ï¼ï¼ˆä¿æŒæ¢¯åº¦ï¼‰
                attended_codes, decoder_cache = model.decoder(
                    primitive_codes,
                    context=image_embed,
                    cache=decoder_cache,
                    return_hiddens=True
                )
            
            # é¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼ˆåªéœ€è¦æœ€åä¸€ä¸ªä½ç½®ï¼‰
            step_embed = attended_codes[:, -1, :]
            
            # é¢„æµ‹å„ä¸ªå±æ€§ï¼ˆä¿æŒæ¢¯åº¦ï¼Œä½¿ç”¨Gumbel Softmaxï¼‰
            gumbel_temp = self.incremental_temperature
            x_logits, x_delta, x_continuous, x_embed = model.predict_attribute_with_continuous_embed(step_embed, 'x', prev_embeds=None, use_gumbel=True, temperature=gumbel_temp)
            y_logits, y_delta, y_continuous, y_embed = model.predict_attribute_with_continuous_embed(step_embed, 'y', prev_embeds=[x_embed], use_gumbel=True, temperature=gumbel_temp)
            z_logits, z_delta, z_continuous, z_embed = model.predict_attribute_with_continuous_embed(step_embed, 'z', prev_embeds=[x_embed, y_embed], use_gumbel=True, temperature=gumbel_temp)
            w_logits, w_delta, w_continuous, w_embed = model.predict_attribute_with_continuous_embed(step_embed, 'w', prev_embeds=[x_embed, y_embed, z_embed], use_gumbel=True, temperature=gumbel_temp)
            h_logits, h_delta, h_continuous, h_embed = model.predict_attribute_with_continuous_embed(step_embed, 'h', prev_embeds=[x_embed, y_embed, z_embed, w_embed], use_gumbel=True, temperature=gumbel_temp)
            l_logits, l_delta, l_continuous, l_embed = model.predict_attribute_with_continuous_embed(step_embed, 'l', prev_embeds=[x_embed, y_embed, z_embed, w_embed, h_embed], use_gumbel=True, temperature=gumbel_temp)
            
            # EOSé¢„æµ‹
            eos_logits = model.to_eos_logits(step_embed).squeeze(-1)
            
            # ä¿å­˜è¿™ä¸€æ­¥çš„è¾“å‡º
            all_logits['x_logits'].append(x_logits)
            all_logits['y_logits'].append(y_logits)
            all_logits['z_logits'].append(z_logits)
            all_logits['w_logits'].append(w_logits)
            all_logits['h_logits'].append(h_logits)
            all_logits['l_logits'].append(l_logits)
            
            all_deltas['x_delta'].append(x_delta)
            all_deltas['y_delta'].append(y_delta)
            all_deltas['z_delta'].append(z_delta)
            all_deltas['w_delta'].append(w_delta)
            all_deltas['h_delta'].append(h_delta)
            all_deltas['l_delta'].append(l_delta)
            
            all_continuous['x_continuous'].append(x_continuous)
            all_continuous['y_continuous'].append(y_continuous)
            all_continuous['z_continuous'].append(z_continuous)
            all_continuous['w_continuous'].append(w_continuous)
            all_continuous['h_continuous'].append(h_continuous)
            all_continuous['l_continuous'].append(l_continuous)
            
            all_eos_logits.append(eos_logits)
            
            # æ„å»ºä¸‹ä¸€æ­¥çš„è¾“å…¥ï¼šå½“å‰token + é¢„æµ‹çš„è¿ç»­å€¼
            # è¿™é‡Œéœ€è¦åˆ›å»ºæ–°çš„embeddingæ¥åŠ å…¥åˆ°åºåˆ—ä¸­
            next_embeds = []
            for attr, continuous_val in [('x', x_continuous), ('y', y_continuous), ('z', z_continuous), 
                                       ('w', w_continuous), ('h', h_continuous), ('l', l_continuous)]:
                # è·å–å¯¹åº”çš„ç¦»æ•£åŒ–å‚æ•°
                num_discrete = getattr(model, f'num_discrete_{attr}')
                continuous_range = getattr(model, f'continuous_range_{attr}')
                
                # ç¦»æ•£åŒ–è¿ç»­å€¼
                attr_discrete = model.discretize(continuous_val, num_discrete, continuous_range)
                attr_embed = getattr(model, f'{attr}_embed')(attr_discrete)
                next_embeds.append(attr_embed)
            
            # ç»„åˆæ‰€æœ‰å±æ€§çš„embedding
            combined_embed = torch.cat(next_embeds, dim=-1)  # [B, total_embed_dim]
            projected_embed = model.project_in(combined_embed).unsqueeze(1)  # [B, 1, model_dim]
            
            # æ›´æ–°å½“å‰åºåˆ—ï¼ˆä¿æŒæ¢¯åº¦ï¼‰
            current_sequence = torch.cat([current_sequence, projected_embed], dim=1)
        
        # 5. ç»„åˆæ‰€æœ‰è¾“å‡º
        result = {
            'logits_dict': {},
            'delta_dict': {},
            'continuous_dict': {},
            'eos_logits': torch.stack(all_eos_logits, dim=1)  # [B, seq_len]
        }
        
        for attr in ['x', 'y', 'z', 'w', 'h', 'l']:
            result['logits_dict'][f'{attr}_logits'] = torch.stack(all_logits[f'{attr}_logits'], dim=1)
            result['delta_dict'][f'{attr}_delta'] = torch.stack(all_deltas[f'{attr}_delta'], dim=1)  
            result['continuous_dict'][f'{attr}_continuous'] = torch.stack(all_continuous[f'{attr}_continuous'], dim=1)
        
        return result
    
 
    
    def _compute_sequence_lengths(self, targets_dict: Dict[str, torch.Tensor]) -> torch.Tensor:
        """è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„çœŸå®åºåˆ—é•¿åº¦"""
        # ä½¿ç”¨xåæ ‡æ¥è®¡ç®—åºåˆ—é•¿åº¦ï¼ˆépaddingçš„ä½ç½®æ•°é‡ï¼‰
        x_targets = targets_dict['x']  # [B, max_boxes]
        batch_size = x_targets.shape[0]
        
        sequence_lengths = []
        for b in range(batch_size):
            # è®¡ç®—épaddingå€¼çš„æ•°é‡ï¼ˆå‡è®¾paddingå€¼ä¸º-1ï¼‰
            valid_mask = x_targets[b] != -1
            seq_len = valid_mask.sum().item()
            sequence_lengths.append(seq_len)
        
        return torch.tensor(sequence_lengths, device=x_targets.device)
    
    def _train_epoch(self, phase: TrainingPhase, epoch_in_phase: int, loss_fn) -> TrainingStats:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        if self.train_sampler:
            self.train_sampler.set_epoch(self.current_epoch)
        
        # è®¡ç®—å½“å‰teacher forcingæ¯”ä¾‹
        teacher_forcing_ratio = self._compute_teacher_forcing_ratio(phase, epoch_in_phase)
        
        total_loss = 0.0
        total_cls_loss = 0.0
        total_iou_loss = 0.0
        total_delta_loss = 0.0
        total_mean_iou = 0.0
        total_adaptive_cls_weight = 0.0
        total_adaptive_delta_weight = 0.0
        num_batches = 0
        
        start_time = time.time()
        
        for batch_idx, batch in enumerate(self.train_loader):
            self.optimizer.zero_grad()
            
            with autocast(enabled=self.use_amp):
                # å‰å‘ä¼ æ’­
                outputs = self._forward_with_sampling_strategy(batch, teacher_forcing_ratio)
                
                # å‡†å¤‡ç›®æ ‡æ•°æ®
                targets = {
                    'x': batch['x'].to(self.device),
                    'y': batch['y'].to(self.device), 
                    'z': batch['z'].to(self.device),
                    'w': batch['w'].to(self.device),
                    'h': batch['h'].to(self.device),
                    'l': batch['l'].to(self.device),
                    'rotations': batch['rotations'].to(self.device),
                }
                
                # è®¡ç®—æŸå¤±
                sequence_lengths = self._compute_sequence_lengths(targets)
                loss_dict = loss_fn(
                    logits_dict=outputs['logits_dict'],
                    delta_dict=outputs['delta_dict'],
                    eos_logits=outputs['eos_logits'],
                    targets_dict=targets,
                    sequence_lengths=sequence_lengths
                )
                
                loss = loss_dict['total_loss']
            
            # åå‘ä¼ æ’­
            if self.use_amp:
                self.scaler.scale(loss).backward()
                # æ¢¯åº¦è£å‰ªï¼ˆæ··åˆç²¾åº¦ï¼‰
                if self.use_grad_clipping:
                    self.scaler.unscale_(self.optimizer)
                    grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss.backward()
                # æ¢¯åº¦è£å‰ªï¼ˆæ™®é€šç²¾åº¦ï¼‰
                if self.use_grad_clipping:
                    grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_cls_loss += loss_dict['total_classification'].item()
            total_iou_loss += loss_dict['iou_loss'].item()
            total_delta_loss += loss_dict['total_delta'].item()
            total_mean_iou += loss_dict['mean_iou'].item()
            total_adaptive_cls_weight += loss_dict.get('adaptive_classification_weight', torch.tensor(0.0)).item()
            total_adaptive_delta_weight += loss_dict.get('adaptive_delta_weight', torch.tensor(0.0)).item()
            num_batches += 1
            
                    # æ—¥å¿—è®°å½• - åªåœ¨ä¸»è¿›ç¨‹æ‰“å°è¯¦ç»†æ—¥å¿—
        log_interval = self.config_loader.get_global_config()['logging']['log_interval']
        if log_interval > 0 and batch_idx % log_interval == 0 and self.is_main_process:
            eos_loss_val = loss_dict.get('eos_loss', torch.tensor(0.0)).item()
            print(f"Epoch {self.current_epoch} [{batch_idx}/{len(self.train_loader)}] "
                  f"Total: {loss.item():.4f} | "
                  f"Cls: {loss_dict['total_classification'].item():.4f} | "
                  f"IoU: {loss_dict['iou_loss'].item():.4f} | "
                  f"Delta: {loss_dict['total_delta'].item():.4f} | "
                  f"EOS: {eos_loss_val:.4f} | "
                  f"TF: {teacher_forcing_ratio:.3f}")
        
        epoch_time = time.time() - start_time
        
        # å­¦ä¹ ç‡è°ƒåº¦
        if self.scheduler:
            self.scheduler.step()
        
        # è¿”å›å¹³å‡ç»Ÿè®¡
        return TrainingStats(
            epoch=self.current_epoch,
            phase=phase.name,
            teacher_forcing_ratio=teacher_forcing_ratio,
            train_loss=total_loss / num_batches,
            train_classification_loss=total_cls_loss / num_batches,
            train_iou_loss=total_iou_loss / num_batches,
            train_delta_loss=total_delta_loss / num_batches,
            train_mean_iou=total_mean_iou / num_batches,
            val_loss=0.0,  # ç¨åå¡«å……
            val_generation_loss=0.0,
            val_mean_iou=0.0,
            val_generation_iou=0.0,
            learning_rate=self.optimizer.param_groups[0]['lr'],
            adaptive_cls_weight=total_adaptive_cls_weight / num_batches,
            adaptive_delta_weight=total_adaptive_delta_weight / num_batches,
            epoch_time=epoch_time
        )
    
    def _validate_epoch(self, loss_fn, phase: TrainingPhase) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepochï¼Œè¿”å›è¯¦ç»†çš„lossç»„ä»¶"""
        self.model.eval()
        
        # Teacher forcingéªŒè¯ç»Ÿè®¡
        total_tf_loss = 0.0
        total_tf_cls_loss = 0.0
        total_tf_iou_loss = 0.0
        total_tf_delta_loss = 0.0
        total_tf_eos_loss = 0.0
        total_tf_iou = 0.0
        
        # ç”ŸæˆéªŒè¯ç»Ÿè®¡
        total_gen_loss = 0.0
        total_gen_iou = 0.0
        total_gen_cls_loss = 0.0
        total_gen_iou_loss = 0.0
        total_gen_delta_loss = 0.0
        total_gen_eos_loss = 0.0
        total_generated_boxes = 0.0
        total_gt_boxes = 0.0
        num_batches = 0

        total_x_error = 0.0
        total_y_error = 0.0
        total_z_error = 0.0
        total_w_error = 0.0
        total_h_error = 0.0
        total_l_error = 0.0
        total_overall_error = 0.0
        
        # ä¿å­˜éªŒè¯æ ·æœ¬çš„æ¨ç†ç»“æœ
        validation_results = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(self.val_loader):
                # 1. Teacher forcingéªŒè¯ (ä¸è®­ç»ƒä¸€è‡´)
                tf_outputs = self._forward_with_sampling_strategy(batch, 1.0)  # å®Œå…¨teacher forcing
                
                targets = {
                    'x': batch['x'].to(self.device),
                    'y': batch['y'].to(self.device),
                    'z': batch['z'].to(self.device),
                    'w': batch['w'].to(self.device),
                    'h': batch['h'].to(self.device),
                    'l': batch['l'].to(self.device),
                    'rotations': batch['rotations'].to(self.device),
                }
                
                sequence_lengths = self._compute_sequence_lengths(targets)
                tf_loss_dict = loss_fn(
                    logits_dict=tf_outputs['logits_dict'],
                    delta_dict=tf_outputs['delta_dict'],
                    eos_logits=tf_outputs['eos_logits'],
                    targets_dict=targets,
                    sequence_lengths=sequence_lengths
                )
                
                # ç´¯ç§¯teacher forcing lossç»„ä»¶
                total_tf_loss += tf_loss_dict['total_loss'].item()
                total_tf_cls_loss += tf_loss_dict['total_classification'].item()
                total_tf_iou_loss += tf_loss_dict['iou_loss'].item()
                total_tf_delta_loss += tf_loss_dict['total_delta'].item()
                total_tf_eos_loss += tf_loss_dict.get('eos_loss', torch.tensor(0.0)).item()
                
                # è®¡ç®—çœŸæ­£çš„è¯„ä¼°IoU (ä½¿ç”¨ä¸ç”ŸæˆéªŒè¯ç›¸åŒçš„æ–¹æ³•)
                eval_iou = self._compute_tf_evaluation_iou(tf_outputs, targets)
                
                # 2. çº¯ç”ŸæˆéªŒè¯
                rgbxyz = batch['image'].to(self.device)
                
                if hasattr(self.model, 'module'):
                    model = self.model.module
                else:
                    model = self.model
                
                # æ ¹æ®é…ç½®é€‰æ‹©æ¨ç†æ–¹æ³•
                if self.use_incremental_inference:
                    # ä½¿ç”¨å¢é‡æ¨ç†è¿›è¡ŒéªŒè¯ç”Ÿæˆï¼ˆæ›´é«˜æ•ˆï¼‰
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®ä¸­çš„æ­£ç¡®max_seq_lenï¼Œè€Œä¸æ˜¯ä¸å­˜åœ¨çš„max_primitive_len
                    max_len = self.config_loader.get_global_config()['max_seq_len']
                    gen_results = model.generate_incremental(
                        image=rgbxyz,
                        max_seq_len=max_len,
                        temperature=self.incremental_temperature
                    )
                else:
                    # ä½¿ç”¨ä¼ ç»Ÿæ¨ç†æ–¹æ³•
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®ä¸­çš„æ­£ç¡®max_seq_len
                    max_len = self.config_loader.get_global_config()['max_seq_len']
                    gen_results = model.generate(
                        image=rgbxyz,
                        max_seq_len=max_len,
                        temperature=1.0
                    )
                # print(f"gen_results: {gen_results}")
                
                # è®¡ç®—ç”Ÿæˆç»“æœçš„è¯¦ç»†æŸå¤±å’Œç»Ÿè®¡ä¿¡æ¯
                gen_metrics = self._compute_generation_metrics(gen_results, targets, loss_fn, verbose=False)
                
                # åˆ é™¤è¿™è¡Œé‡å¤çš„ç´¯ç§¯
                # total_tf_loss += tf_loss_dict['total_loss'].item()
                
                total_tf_iou += eval_iou  # ä½¿ç”¨è¯„ä¼°IoUè€Œä¸æ˜¯æŸå¤±IoU
                total_gen_iou += gen_metrics['iou']
                total_generated_boxes += gen_metrics['num_generated_boxes']
                total_gt_boxes += gen_metrics['num_gt_boxes']
                
                # ç´¯ç§¯ç»´åº¦è¯¯å·®
                total_x_error += gen_metrics['x_error']
                total_y_error += gen_metrics['y_error']
                total_z_error += gen_metrics['z_error']
                total_w_error += gen_metrics['w_error']
                total_h_error += gen_metrics['h_error']
                total_l_error += gen_metrics['l_error']
                total_overall_error += gen_metrics['overall_mean_error']
                
                num_batches += 1
                
                # ä¿å­˜æŒ‡å®šæ ·æœ¬çš„éªŒè¯ç»“æœ
                if batch_idx in self.validation_samples and self.is_main_process:
                    validation_results.append({
                        'batch_idx': batch_idx,
                        'epoch': self.current_epoch,
                        'phase': phase.name,
                        'generation_results': gen_results,
                        'ground_truth': targets,
                        'tf_loss': tf_loss_dict['total_loss'].item(),
                        'gen_iou': gen_metrics['iou'],
                        'image_shape': rgbxyz.shape
                    })
        
        # ä¿å­˜éªŒè¯ç»“æœ - åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜
        if validation_results and self.is_main_process:
            results_file = self.validation_dir / f"validation_epoch_{self.current_epoch:04d}.json"
            with open(results_file, 'w') as f:
                # å°†tensorè½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                serializable_results = []
                for result in validation_results:
                    serializable_result = {}
                    for key, value in result.items():
                        if isinstance(value, torch.Tensor):
                            serializable_result[key] = value.detach().cpu().tolist()
                        elif isinstance(value, dict):
                            serializable_result[key] = {k: v.detach().cpu().tolist() if isinstance(v, torch.Tensor) else v 
                                                      for k, v in value.items()}
                        else:
                            serializable_result[key] = value
                    serializable_results.append(serializable_result)
                
                json.dump(serializable_results, f, indent=2)
        
        # è®¡ç®—å¹³å‡å€¼å¹¶è¿”å›è¯¦ç»†lossç»„ä»¶
        avg_tf_loss = total_tf_loss / num_batches if num_batches > 0 else 0.0
        avg_tf_cls_loss = total_tf_cls_loss / num_batches if num_batches > 0 else 0.0
        avg_tf_iou_loss = total_tf_iou_loss / num_batches if num_batches > 0 else 0.0
        avg_tf_delta_loss = total_tf_delta_loss / num_batches if num_batches > 0 else 0.0
        avg_tf_eos_loss = total_tf_eos_loss / num_batches if num_batches > 0 else 0.0
        avg_tf_iou = total_tf_iou / num_batches if num_batches > 0 else 0.0
        
        # ç§»é™¤è™šå‡çš„ç”ŸæˆæŸå¤±è®¡ç®—
        # avg_gen_loss = total_gen_loss / num_batches if num_batches > 0 else 0.0
        # avg_gen_cls_loss = total_gen_cls_loss / num_batches if num_batches > 0 else 0.0
        # avg_gen_iou_loss = total_gen_iou_loss / num_batches if num_batches > 0 else 0.0
        # avg_gen_delta_loss = total_gen_delta_loss / num_batches if num_batches > 0 else 0.0
        # avg_gen_eos_loss = total_gen_eos_loss / num_batches if num_batches > 0 else 0.0
        
        avg_gen_iou = total_gen_iou / num_batches if num_batches > 0 else 0.0
        avg_generated_boxes = total_generated_boxes / num_batches if num_batches > 0 else 0.0
        avg_gt_boxes = total_gt_boxes / num_batches if num_batches > 0 else 0.0
        
        # è®¡ç®—å¹³å‡è¯¯å·®
        avg_x_error = total_x_error / num_batches if num_batches > 0 else 0.0
        avg_y_error = total_y_error / num_batches if num_batches > 0 else 0.0
        avg_z_error = total_z_error / num_batches if num_batches > 0 else 0.0
        avg_w_error = total_w_error / num_batches if num_batches > 0 else 0.0
        avg_h_error = total_h_error / num_batches if num_batches > 0 else 0.0
        avg_l_error = total_l_error / num_batches if num_batches > 0 else 0.0
        avg_overall_error = total_overall_error / num_batches if num_batches > 0 else 0.0
        
        # è¿”å›ç»“æœ - ç§»é™¤è™šå‡çš„æŸå¤±å€¼
        return {
            'tf_total_loss': avg_tf_loss,
            'tf_classification_loss': avg_tf_cls_loss,
            'tf_iou_loss': avg_tf_iou_loss,
            'tf_delta_loss': avg_tf_delta_loss,
            'tf_eos_loss': avg_tf_eos_loss,
            'tf_mean_iou': avg_tf_iou,
            'generation_iou': avg_gen_iou,
            'avg_generated_boxes': avg_generated_boxes,
            'avg_gt_boxes': avg_gt_boxes,
            'avg_x_error': avg_x_error,
            'avg_y_error': avg_y_error,
            'avg_z_error': avg_z_error,
            'avg_w_error': avg_w_error,
            'avg_h_error': avg_h_error,
            'avg_l_error': avg_l_error,
            'avg_overall_error': avg_overall_error
        }
    
    def _compute_tf_evaluation_iou(self, outputs: Dict, targets: Dict, verbose: bool = False) -> float:
        """è®¡ç®—TFè¯„ä¼°IoUï¼Œä½¿ç”¨ä¸€å¯¹ä¸€åŒ¹é…ç­–ç•¥"""
        try:
            batch_size = targets['x'].size(0)
            total_iou = 0.0
            valid_samples = 0
            
            for b in range(batch_size):
                # æ„å»ºé¢„æµ‹çš„3D boxes
                pred_boxes = []
                gt_boxes = []
                gt_rotations = []
                
                # è·å–æ¯ä¸ªä½ç½®çš„é¢„æµ‹å€¼
                seq_len = targets['x'].size(1)
                for s in range(seq_len):
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆä½ç½®ï¼ˆépaddingï¼‰
                    if targets['x'][b, s].item() != -1.0:
                        # å°†logitså’Œdeltaè½¬æ¢ä¸ºè¿ç»­é¢„æµ‹å€¼
                        pred_box = []
                        for attr in ['x', 'y', 'z', 'w', 'h', 'l']:
                            if attr + '_logits' in outputs['logits_dict'] and attr + '_delta' in outputs['delta_dict']:
                                logits = outputs['logits_dict'][attr + '_logits'][b, s]  # [num_bins]
                                delta = outputs['delta_dict'][attr + '_delta'][b, s]     # scalar
                                continuous_val = self._get_continuous_prediction(logits, delta, attr)
                                pred_box.append(continuous_val)
                        
                        if len(pred_box) == 6:
                            pred_boxes.append(pred_box)
                            
                            # å¯¹åº”çš„GT box
                            gt_box = [
                                targets['x'][b, s].cpu().item(),
                                targets['y'][b, s].cpu().item(),
                                targets['z'][b, s].cpu().item(),
                                targets['w'][b, s].cpu().item(),
                                targets['h'][b, s].cpu().item(),
                                targets['l'][b, s].cpu().item(),
                            ]
                            gt_boxes.append(gt_box)
                            
                            # GTæ—‹è½¬ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                            if 'rotations' in targets:
                                gt_rot = targets['rotations'][b, s].cpu().numpy()  # [4] quaternion
                                gt_rotations.append(gt_rot)
                            else:
                                # ä½¿ç”¨å•ä½å››å…ƒæ•°ï¼ˆæ— æ—‹è½¬ï¼‰
                                gt_rotations.append([0.0, 0.0, 0.0, 1.0])
                
                # è®¡ç®—è¯¥æ ·æœ¬çš„IoU
                if pred_boxes and gt_boxes:
                    sample_ious = []
                    
                    # è®¡ç®—æ¯ä¸ªé¢„æµ‹boxä¸å¯¹åº”GT boxçš„IoU
                    for i, (pred_box, gt_box, gt_rot) in enumerate(zip(pred_boxes, gt_boxes, gt_rotations)):
                        try:
                            # ä½¿ç”¨AABB IoUè®¡ç®—
                            iou = self._compute_box_iou(pred_box, gt_box, gt_rot)
                            sample_ious.append(iou)
                            
                        except Exception as e:
                            print(f"âš ï¸  è®¡ç®—box IoUæ—¶å‡ºé”™: {e}")
                            sample_ious.append(0.0)
                    
                    if sample_ious:
                        sample_mean_iou = sum(sample_ious) / len(sample_ious)
                        total_iou += sample_mean_iou
                        valid_samples += 1
                        if verbose:  # åªåœ¨verbose=Trueæ—¶æ‰“å°
                            print(f"ğŸ“Š TF Sample {b}: Mean IoU = {sample_mean_iou:.4f} ({len(sample_ious)} boxes)")
            
            if valid_samples == 0:
                return 0.0
            
            mean_iou = total_iou / valid_samples
            if verbose:  # åªåœ¨verbose=Trueæ—¶æ‰“å°
                print(f"\nğŸ¯ TF Overall Mean IoU: {mean_iou:.4f} (from {valid_samples} samples)")
            return float(mean_iou)
            
        except Exception as e:
            if verbose:
                print(f"âš ï¸  è®¡ç®—TFè¯„ä¼°IoUæ—¶å‡ºé”™: {e}")
            return 0.0
    
    def _get_continuous_prediction(self, logits: torch.Tensor, delta: torch.Tensor, attr: str) -> float:
        """å°†åˆ†ç±»logitså’Œdeltaç»„åˆæˆè¿ç»­é¢„æµ‹å€¼"""
        # è·å–å±æ€§çš„é…ç½®ï¼ˆä»ConfigLoaderè¿”å›çš„å¹³é“ºç»“æ„ä¸­è·å–ï¼‰
        attr_configs = {
            'x': (self.model_config.get('num_discrete_x', 128), 
                  self.model_config.get('continuous_range_x', [0.5, 2.5])),
            'y': (self.model_config.get('num_discrete_y', 128), 
                  self.model_config.get('continuous_range_y', [-2.0, 2.0])),
            'z': (self.model_config.get('num_discrete_z', 128), 
                  self.model_config.get('continuous_range_z', [-1.5, 1.5])),
            'w': (self.model_config.get('num_discrete_w', 64), 
                  self.model_config.get('continuous_range_w', [0.1, 1.0])),
            'h': (self.model_config.get('num_discrete_h', 64), 
                  self.model_config.get('continuous_range_h', [0.1, 1.0])),
            'l': (self.model_config.get('num_discrete_l', 64), 
                  self.model_config.get('continuous_range_l', [0.1, 1.0]))
        }
        
        num_bins, value_range = attr_configs[attr]
        min_val, max_val = value_range
        
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„binå†…offseté€»è¾‘
        # è·å–åˆ†ç±»é¢„æµ‹ï¼ˆç¡®å®šæ€§é‡‡æ ·ï¼‰
        discrete_pred = torch.argmax(logits).item()
        
        # è®¡ç®—bin_widthå’Œè¿ç»­å€¼
        bin_width = (max_val - min_val) / (num_bins - 1)
        continuous_base = min_val + discrete_pred * bin_width
        
        # ç¡®ä¿deltaåœ¨CPUä¸Šï¼Œå¹¶æ­£ç¡®ç¼©æ”¾ä¸ºbinå†…offset
        if delta.is_cuda:
            delta_val = float(delta.cpu().detach()) * bin_width
        else:
            delta_val = float(delta.detach()) * bin_width
        
        return continuous_base + delta_val

    def _compute_generation_metrics(self, gen_results: Dict, targets: Dict, loss_fn, verbose: bool = False) -> Dict[str, float]:
        """
        è®¡ç®—ç”Ÿæˆç»“æœçš„è¯¦ç»†æŒ‡æ ‡
        Args:
            gen_results: ç”Ÿæˆç»“æœå­—å…¸ï¼ˆå·²ç»æ˜¯è¿ç»­å€¼ï¼‰
            targets: ç›®æ ‡å€¼å­—å…¸
            loss_fn: æŸå¤±å‡½æ•°ï¼ˆä¸ä½¿ç”¨ï¼Œå› ä¸ºgen_resultsä¸æ˜¯æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        Returns:
            metrics: åŒ…å«å„é¡¹ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # ç”Ÿæˆç»“æœå·²ç»æ˜¯è¿ç»­å€¼ï¼Œç›´æ¥ä½¿ç”¨
            processed_gen_results = {}
            target_seq_len = targets['x'].shape[1]  # GTçš„åºåˆ—é•¿åº¦
            
            for attr in ['x', 'y', 'z', 'w', 'h', 'l']:
                if attr in gen_results:
                    # è·å–ç”Ÿæˆç»“æœï¼ˆå·²ç»æ˜¯è¿ç»­å€¼ï¼‰
                    gen_values = gen_results[attr]  # [B, seq_len]
                    
                    # å¯¹é½åºåˆ—é•¿åº¦
                    if gen_values.shape[1] > target_seq_len:
                        gen_values = gen_values[:, :target_seq_len]
                    elif gen_values.shape[1] < target_seq_len:
                        # ç”¨é›¶å¡«å……
                        padding_length = target_seq_len - gen_values.shape[1]
                        padding = torch.zeros(gen_values.shape[0], padding_length, device=gen_values.device)
                        gen_values = torch.cat([gen_values, padding], dim=1)
                    
                    processed_gen_results[attr] = gen_values
                else:
                    # å¦‚æœæŸä¸ªå±æ€§ç¼ºå¤±ï¼Œä½¿ç”¨é›¶å¡«å……
                    processed_gen_results[attr] = torch.zeros(targets[attr].shape, device=targets[attr].device)
            
            # è®¡ç®—IoU
            gen_iou = self._compute_generation_iou(processed_gen_results, targets, verbose)
            
            # è®¡ç®—6ä¸ªç»´åº¦çš„å¹³å‡è¯¯å·®
            dimension_errors = {}
            total_valid_predictions = 0
            
            for attr in ['x', 'y', 'z', 'w', 'h', 'l']:
                if attr in processed_gen_results and attr in targets:
                    # è·å–ç”Ÿæˆç»“æœå’Œç›®æ ‡å€¼
                    gen_values = processed_gen_results[attr]  # [B, seq_len]
                    gt_values = targets[attr]                  # [B, seq_len]
                    
                    # åˆ›å»ºæœ‰æ•ˆmaskï¼ˆæ’é™¤paddingå€¼ï¼‰
                    valid_mask = (gt_values != -1.0) & (gt_values != 0.0)  # GTépaddingä¸”éé›¶
                    
                    if valid_mask.sum() > 0:
                        # è®¡ç®—æœ‰æ•ˆä½ç½®çš„ç»å¯¹è¯¯å·®
                        abs_errors = torch.abs(gen_values - gt_values)
                        valid_errors = abs_errors[valid_mask]
                        
                        # è®¡ç®—å¹³å‡è¯¯å·®
                        mean_error = valid_errors.mean().item()
                        dimension_errors[f'{attr}_error'] = mean_error
                        total_valid_predictions += valid_mask.sum().item()
                    else:
                        dimension_errors[f'{attr}_error'] = 0.0
                else:
                    dimension_errors[f'{attr}_error'] = 0.0
            
            # è®¡ç®—æ€»ä½“å¹³å‡è¯¯å·®
            if total_valid_predictions > 0:
                overall_mean_error = sum(dimension_errors.values()) / 6.0
            else:
                overall_mean_error = 0.0
            
            # ç»Ÿè®¡ç”Ÿæˆçš„ç®±å­æ•°é‡ vs GTç®±å­æ•°é‡
            num_generated_boxes = 0
            num_gt_boxes = 0
            
            batch_size = targets['x'].shape[0]
            for b in range(batch_size):
                # ç»Ÿè®¡GTç®±å­æ•°é‡ (épaddingçš„ä½ç½®)
                gt_valid = (targets['x'][b] != -1.0).sum().item()
                num_gt_boxes += gt_valid
                
                # ç»Ÿè®¡ç”Ÿæˆçš„ç®±å­æ•°é‡ (ç®€åŒ–ï¼šæ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æœ‰æ•ˆåæ ‡)
                if 'x' in processed_gen_results:
                    gen_valid = (processed_gen_results['x'][b] != 0.0).sum().item()  # å‡è®¾0ä¸ºå¡«å……å€¼
                    num_generated_boxes += gen_valid
            
            # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡ - ç§»é™¤è™šå‡çš„æŸå¤±å€¼
            metrics = {
                'iou': gen_iou,
                'num_generated_boxes': num_generated_boxes,
                'num_gt_boxes': num_gt_boxes,
                'overall_mean_error': overall_mean_error,
                'x_error': dimension_errors['x_error'],
                'y_error': dimension_errors['y_error'],
                'z_error': dimension_errors['z_error'],
                'w_error': dimension_errors['w_error'],
                'h_error': dimension_errors['h_error'],
                'l_error': dimension_errors['l_error']
            }
            
            return metrics
            
        except Exception as e:
            print(f"âš ï¸  è®¡ç®—ç”ŸæˆæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            # è¿”å›é»˜è®¤å€¼
            return {
                'iou': 0.0,
                'num_generated_boxes': 0,
                'num_gt_boxes': 0,
                'overall_mean_error': 1.0,
                'x_error': 1.0,
                'y_error': 1.0,
                'z_error': 1.0,
                'w_error': 1.0,
                'h_error': 1.0,
                'l_error': 1.0
            }
    
    def _compute_generation_iou(self, gen_results: Dict, targets: Dict, verbose: bool = False) -> float:
        """è®¡ç®—ç”Ÿæˆç»“æœä¸ç›®æ ‡çš„IoUï¼Œä½¿ç”¨ä¸€å¯¹ä¸€åŒ¹é…ç­–ç•¥"""
        try:
            # æ£€æŸ¥ç”Ÿæˆç»“æœ
            if not gen_results or gen_results['x'].shape[1] == 0:
                return 0.0
            
            batch_size = targets['x'].size(0)
            total_iou = 0.0
            valid_samples = 0
            
            for b in range(batch_size):
                # æ„å»ºé¢„æµ‹boxeså’ŒGT boxesçš„ä¸€å¯¹ä¸€åŒ¹é…
                pred_boxes = []
                gt_boxes = []
                gt_rotations = []
                
                # è·å–åºåˆ—é•¿åº¦
                seq_len = targets['x'].size(1)
                gen_len = gen_results['x'].shape[1]
                
                # ä¸€å¯¹ä¸€åŒ¹é…ï¼šåªè®¡ç®—åŒæ—¶å­˜åœ¨çš„ä½ç½®
                for s in range(seq_len):
                    # æ£€æŸ¥GTæ˜¯å¦ä¸ºæœ‰æ•ˆä½ç½®ï¼ˆépaddingï¼‰ä¸”ç”Ÿæˆç»“æœä¸­ä¹Ÿå­˜åœ¨è¯¥ä½ç½®
                    if targets['x'][b, s].item() != -1.0 and s < gen_len:
                        # GT box
                        gt_box = [
                            targets['x'][b, s].cpu().item(),
                            targets['y'][b, s].cpu().item(),
                            targets['z'][b, s].cpu().item(),
                            targets['w'][b, s].cpu().item(),
                            targets['h'][b, s].cpu().item(),
                            targets['l'][b, s].cpu().item(),
                        ]
                        gt_boxes.append(gt_box)
                        
                        # GTæ—‹è½¬ä¿¡æ¯
                        if 'rotations' in targets:
                            gt_rot = [
                                targets['rotations'][b, s, 0].cpu().item(),
                                targets['rotations'][b, s, 1].cpu().item(),
                                targets['rotations'][b, s, 2].cpu().item(),
                                targets['rotations'][b, s, 3].cpu().item(),
                            ]
                            gt_rotations.append(gt_rot)
                        else:
                            gt_rotations.append([0.0, 0.0, 0.0, 1.0])  # å•ä½å››å…ƒæ•°
                        
                        # å¯¹åº”çš„é¢„æµ‹box - ä¿®å¤è®¿é—®æ ¼å¼
                        pred_box = [
                            float(gen_results['x'][b, s]),
                            float(gen_results['y'][b, s]),
                            float(gen_results['z'][b, s]),
                            float(gen_results['w'][b, s]),
                            float(gen_results['h'][b, s]),
                            float(gen_results['l'][b, s]),
                        ]
                        pred_boxes.append(pred_box)
                
                # è®¡ç®—è¯¥æ ·æœ¬çš„IoUï¼ˆä¸€å¯¹ä¸€åŒ¹é…ï¼‰
                if pred_boxes and gt_boxes:
                    sample_ious = []
                    
                    # è®¡ç®—æ¯ä¸ªé¢„æµ‹boxä¸å¯¹åº”GT boxçš„IoU
                    for i, (pred_box, gt_box, gt_rot) in enumerate(zip(pred_boxes, gt_boxes, gt_rotations)):
                        try:
                            # ä½¿ç”¨AABB IoUè®¡ç®—
                            iou = self._compute_box_iou(pred_box, gt_box, gt_rot)
                            sample_ious.append(iou)
                            
                        except Exception as e:
                            print(f"âš ï¸  è®¡ç®—box IoUæ—¶å‡ºé”™: {e}")
                            sample_ious.append(0.0)
                    
                    if sample_ious:
                        sample_mean_iou = sum(sample_ious) / len(sample_ious)
                        total_iou += sample_mean_iou
                        valid_samples += 1
                        if verbose:  # åªåœ¨verbose=Trueæ—¶æ‰“å°æ¯ä¸ªsampleçš„IoU
                            print(f"ğŸ“Š Generation Sample {b}: Mean IoU = {sample_mean_iou:.4f} ({len(sample_ious)} boxes)")
            
            if valid_samples == 0:
                return 0.0
            
            mean_iou = total_iou / valid_samples
            if verbose:  # åªåœ¨verbose=Trueæ—¶æ‰“å°æ€»ä½“IoU
                print(f"\nğŸ¯ Generation Overall Mean IoU: {mean_iou:.4f} (from {valid_samples} samples)")
            return float(mean_iou)
            
        except Exception as e:
            if verbose:
                print(f"è®¡ç®—ç”ŸæˆIoUæ—¶å‡ºé”™: {e}")
            return 0.0
    
    def _compute_box_iou(self, box1: List[float], box2: List[float], rot1: List[float] = None, rot2: List[float] = None) -> float:
        """
        è®¡ç®—ä¸¤ä¸ª3D boxçš„IoUï¼Œç»Ÿä¸€ä½¿ç”¨AABBè®¡ç®—
        Args:
            box1: [x, y, z, w, h, l] - ç¬¬ä¸€ä¸ªboxçš„ä¸­å¿ƒåæ ‡å’Œå°ºå¯¸
            box2: [x, y, z, w, h, l] - ç¬¬äºŒä¸ªboxçš„ä¸­å¿ƒåæ ‡å’Œå°ºå¯¸ 
            rot1: [qx, qy, qz, qw] - ç¬¬ä¸€ä¸ªboxçš„å››å…ƒæ•°æ—‹è½¬ï¼ˆå¿½ç•¥ï¼‰
            rot2: [qx, qy, qz, qw] - ç¬¬äºŒä¸ªboxçš„å››å…ƒæ•°æ—‹è½¬ï¼ˆå¿½ç•¥ï¼‰
        Returns:
            IoUå€¼ (0.0-1.0)
        """
        # ç›´æ¥ä½¿ç”¨AABB IoUè®¡ç®—ï¼Œå¿½ç•¥æ—‹è½¬ä¿¡æ¯
        return self._compute_simple_aabb_iou(box1, box2)
    
    def _compute_simple_aabb_iou(self, box1: List[float], box2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè½´å¯¹é½boxçš„IoU"""
        try:
            # ç¡®ä¿boxæ ¼å¼æ­£ç¡®
            if len(box1) != 6 or len(box2) != 6:
                print(f"âš ï¸  Boxæ ¼å¼é”™è¯¯: box1é•¿åº¦={len(box1)}, box2é•¿åº¦={len(box2)}")
                return 0.0
                
            x1, y1, z1, w1, h1, l1 = box1
            x2, y2, z2, w2, h2, l2 = box2
            
            # è®¡ç®—è¾¹ç•Œ
            x1_min, x1_max = x1 - w1/2, x1 + w1/2
            y1_min, y1_max = y1 - h1/2, y1 + h1/2
            z1_min, z1_max = z1 - l1/2, z1 + l1/2
            
            x2_min, x2_max = x2 - w2/2, x2 + w2/2
            y2_min, y2_max = y2 - h2/2, y2 + h2/2
            z2_min, z2_max = z2 - l2/2, z2 + l2/2
            
            # è®¡ç®—äº¤é›†ï¼ˆä½¿ç”¨æ­£ç¡®çš„é€»è¾‘ï¼‰
            inter_x = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))
            inter_y = max(0, min(y1_max, y2_max) - max(y1_min, y2_min))
            inter_z = max(0, min(z1_max, z2_max) - max(z1_min, z2_min))
            
            # è®¡ç®—ä½“ç§¯
            inter_volume = inter_x * inter_y * inter_z
            volume1 = w1 * h1 * l1
            volume2 = w2 * h2 * l2
            union_volume = volume1 + volume2 - inter_volume
            
            if union_volume <= 0:
                return 0.0
                
            iou = inter_volume / union_volume
            return max(0.0, min(1.0, iou))  # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…
            
        except Exception as e:
            print(f"è½´å¯¹é½IoUè®¡ç®—å‡ºé”™: {e}")
            return 0.0
    
    def _quaternion_to_rotation_matrix(self, quat: List[float]) -> np.ndarray:
        """å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ"""
        import numpy as np
        
        if len(quat) != 4:
            return np.eye(3)
            
        qx, qy, qz, qw = quat
        
        # æ ‡å‡†åŒ–å››å…ƒæ•°
        norm = np.sqrt(qx**2 + qy**2 + qz**2 + qw**2)
        if norm == 0:
            return np.eye(3)
        qx, qy, qz, qw = qx/norm, qy/norm, qz/norm, qw/norm
        
        # å››å…ƒæ•°åˆ°æ—‹è½¬çŸ©é˜µçš„è½¬æ¢
        R = np.array([
            [1 - 2*(qy**2 + qz**2), 2*(qx*qy - qw*qz), 2*(qx*qz + qw*qy)],
            [2*(qx*qy + qw*qz), 1 - 2*(qx**2 + qz**2), 2*(qy*qz - qw*qx)],
            [2*(qx*qz - qw*qy), 2*(qy*qz + qw*qx), 1 - 2*(qx**2 + qy**2)]
        ])
        
        return R
    
    def _compute_axis_aligned_iou(self, box1: List[float], box2: List[float]) -> float:
        """è®¡ç®—axis-aligned boxçš„IoUï¼ˆåŸå§‹å®ç°ï¼‰"""
        x1, y1, z1, w1, h1, l1 = box1
        x2, y2, z2, w2, h2, l2 = box2
        
        # è®¡ç®—è¾¹ç•Œ
        x1_min, x1_max = x1 - w1/2, x1 + w1/2
        y1_min, y1_max = y1 - h1/2, y1 + h1/2
        z1_min, z1_max = z1 - l1/2, z1 + l1/2
        
        x2_min, x2_max = x2 - w2/2, x2 + w2/2
        y2_min, y2_max = y2 - h2/2, y2 + h2/2
        z2_min, z2_max = z2 - l2/2, z2 + l2/2
        
        # è®¡ç®—äº¤é›†
        inter_x = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))
        inter_y = max(0, min(y1_max, y2_max) - max(y1_min, y2_min))
        inter_z = max(0, min(z1_max, z2_max) - max(z1_min, z2_min))
        
        inter_volume = inter_x * inter_y * inter_z
        
        # è®¡ç®—å¹¶é›†
        vol1 = w1 * h1 * l1
        vol2 = w2 * h2 * l2
        union_volume = vol1 + vol2 - inter_volume
        
        if union_volume <= 0:
            return 0.0
        
        return inter_volume / union_volume
    
    def _compute_oriented_box_iou_sampling(self, center1, size1, R1, center2, size2, R2, samples_per_dim=20):
        """
        ä½¿ç”¨é‡‡æ ·æ–¹æ³•è®¡ç®—æ—‹è½¬boxçš„IoU
        é€šè¿‡åœ¨3Dç©ºé—´ä¸­å¯†é›†é‡‡æ ·ç‚¹æ¥è¿‘ä¼¼è®¡ç®—äº¤é›†ä½“ç§¯
        """
        import numpy as np
        
        # è®¡ç®—ä¸¤ä¸ªboxçš„ä½“ç§¯
        vol1 = size1[0] * size1[1] * size1[2]
        vol2 = size2[0] * size2[1] * size2[2]
        
        if vol1 <= 0 or vol2 <= 0:
            return 0.0
        
        # ç¡®å®šé‡‡æ ·åŒºåŸŸï¼ˆä¸¤ä¸ªboxçš„åŒ…å›´ç›’ï¼‰
        corners1 = self._get_box_corners(center1, size1, R1)
        corners2 = self._get_box_corners(center2, size2, R2)
        
        all_corners = np.vstack([corners1, corners2])
        min_coords = np.min(all_corners, axis=0)
        max_coords = np.max(all_corners, axis=0)
        
        # æ‰©å±•é‡‡æ ·åŒºåŸŸä¸€ç‚¹ç‚¹ï¼Œç¡®ä¿åŒ…å«è¾¹ç•Œ
        margin = 0.01
        min_coords -= margin
        max_coords += margin
        
        # ç”Ÿæˆé‡‡æ ·ç‚¹
        x = np.linspace(min_coords[0], max_coords[0], samples_per_dim)
        y = np.linspace(min_coords[1], max_coords[1], samples_per_dim)
        z = np.linspace(min_coords[2], max_coords[2], samples_per_dim)
        
        # è®¡ç®—é‡‡æ ·ä½“ç§¯å…ƒç´ 
        dx = (max_coords[0] - min_coords[0]) / samples_per_dim
        dy = (max_coords[1] - min_coords[1]) / samples_per_dim
        dz = (max_coords[2] - min_coords[2]) / samples_per_dim
        dV = dx * dy * dz
        
        # æ£€æŸ¥æ¯ä¸ªé‡‡æ ·ç‚¹æ˜¯å¦åœ¨ä¸¤ä¸ªboxå†…
        intersection_count = 0
        union_count = 0
        
        for xi in x:
            for yi in y:
                for zi in z:
                    point = np.array([xi, yi, zi])
                    
                    in_box1 = self._point_in_oriented_box(point, center1, size1, R1)
                    in_box2 = self._point_in_oriented_box(point, center2, size2, R2)
                    
                    if in_box1 and in_box2:
                        intersection_count += 1
                    
                    if in_box1 or in_box2:
                        union_count += 1
        
        if union_count == 0:
            return 0.0
        
        # è®¡ç®—IoU
        intersection_volume = intersection_count * dV
        union_volume = vol1 + vol2 - intersection_volume
        
        if union_volume <= 0:
            return 0.0
        
        iou = intersection_volume / union_volume
        
        # è°ƒè¯•ä¿¡æ¯ï¼šå½“IoUå¼‚å¸¸æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
        if iou < 0 or iou > 1:
            print(f"âš ï¸  å¼‚å¸¸IoUå€¼: {iou:.6f}")
            print(f"  intersection_count: {intersection_count}, dV: {dV:.6f}")
            print(f"  vol1: {vol1:.6f}, vol2: {vol2:.6f}")
            print(f"  intersection_volume: {intersection_volume:.6f}")
            print(f"  union_volume: {union_volume:.6f}")
            # å¼ºåˆ¶é™åˆ¶åœ¨[0,1]èŒƒå›´å†…
            iou = max(0.0, min(1.0, iou))
        
        return iou
    
    def _get_box_corners(self, center, size, R):
        """è·å–æ—‹è½¬boxçš„8ä¸ªé¡¶ç‚¹åæ ‡"""
        import numpy as np
        
        # boxåœ¨å±€éƒ¨åæ ‡ç³»ä¸­çš„8ä¸ªé¡¶ç‚¹
        w, h, l = size
        local_corners = np.array([
            [-w/2, -h/2, -l/2],
            [+w/2, -h/2, -l/2],
            [+w/2, +h/2, -l/2],
            [-w/2, +h/2, -l/2],
            [-w/2, -h/2, +l/2],
            [+w/2, -h/2, +l/2],
            [+w/2, +h/2, +l/2],
            [-w/2, +h/2, +l/2],
        ])
        
        # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
        world_corners = (R @ local_corners.T).T + center
        return world_corners
    
    def _point_in_oriented_box(self, point, center, size, R):
        """æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨æ—‹è½¬çš„boxå†…"""
        import numpy as np
        
        # å°†ç‚¹è½¬æ¢åˆ°boxçš„å±€éƒ¨åæ ‡ç³»
        local_point = R.T @ (point - center)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å±€éƒ¨åæ ‡ç³»çš„è¾¹ç•Œå†…
        w, h, l = size
        return (abs(local_point[0]) <= w/2 and 
                abs(local_point[1]) <= h/2 and 
                abs(local_point[2]) <= l/2)
    
    def _test_inference(self) -> Dict[str, float]:
        """åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨ç†ï¼Œè®¡ç®—æŒ‡æ ‡å¹¶ä¿å­˜ç»“æœ"""
        if self.is_main_process:
            print("ğŸ§ª å¼€å§‹æµ‹è¯•é›†æ¨ç†...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
        test_loader = create_dataloader(
            data_root=self.config_loader.get('data.dataset.data_root'),
            stage="test",
            batch_size=1,  # æµ‹è¯•æ—¶ä½¿ç”¨batch_size=1
            max_boxes=self.config_loader.get('global.max_seq_len'),
            image_size=self.config_loader.get('global.image_size'),
            continuous_ranges=self.config_loader.get('data.dataset.continuous_ranges'),
            augmentation_config={},  # æµ‹è¯•æ—¶ä¸ä½¿ç”¨æ•°æ®å¢å¼º
            num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨å•è¿›ç¨‹
            pin_memory=False,
            prefetch_factor=2,
            persistent_workers=False
        )
        
        self.model.eval()
        
        # æµ‹è¯•ç»Ÿè®¡
        total_gen_iou = 0.0
        total_generated_boxes = 0.0
        total_gt_boxes = 0.0
        total_x_error = 0.0
        total_y_error = 0.0
        total_z_error = 0.0
        total_w_error = 0.0
        total_h_error = 0.0
        total_l_error = 0.0
        total_overall_error = 0.0
        num_batches = 0
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        test_results = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(test_loader):
                if self.is_main_process:
                    print(f"  ğŸ“Š å¤„ç†æµ‹è¯•æ ·æœ¬ {batch_idx + 1}/{len(test_loader)}")
                
                # å‡†å¤‡è¾“å…¥æ•°æ®
                rgbxyz = batch['image'].to(self.device)
                targets = {
                    'x': batch['x'].to(self.device),
                    'y': batch['y'].to(self.device),
                    'z': batch['z'].to(self.device),
                    'w': batch['w'].to(self.device),
                    'h': batch['h'].to(self.device),
                    'l': batch['l'].to(self.device),
                    'rotations': batch['rotations'].to(self.device),
                }
                
                # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œç”Ÿæˆ
                if hasattr(self.model, 'module'):
                    model = self.model.module
                else:
                    model = self.model
                
                try:
                    # æ£€æŸ¥è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§
                    if torch.isnan(rgbxyz).any() or torch.isinf(rgbxyz).any():
                        if self.is_main_process:
                            print(f"  âš ï¸  è¾“å…¥æ•°æ®åŒ…å«NaNæˆ–Infå€¼ï¼Œè·³è¿‡æ­¤æ ·æœ¬")
                        continue
                    
                    # æ ¹æ®é…ç½®é€‰æ‹©æ¨ç†æ–¹æ³•
                    if self.use_incremental_inference:
                        # ä½¿ç”¨å¢é‡æ¨ç†è¿›è¡Œæµ‹è¯•ç”Ÿæˆï¼ˆæ›´é«˜æ•ˆï¼‰
                        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„max_seq_lenå‚æ•°
                        max_len = self.config_loader.get_global_config()['max_seq_len']
                        gen_results = model.generate_incremental(
                            image=rgbxyz,
                            max_seq_len=max_len,
                            temperature=self.incremental_temperature
                        )
                    else:
                        # ä½¿ç”¨ä¼ ç»Ÿæ¨ç†æ–¹æ³•
                        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„max_seq_lenå‚æ•°
                        max_len = self.config_loader.get_global_config()['max_seq_len']
                        gen_results = model.generate(
                            image=rgbxyz,
                            max_seq_len=max_len,
                            temperature=1.0
                        )
                    
                    # æ£€æŸ¥ç”Ÿæˆç»“æœçš„æœ‰æ•ˆæ€§
                    if not gen_results or not isinstance(gen_results, dict):
                        if self.is_main_process:
                            print(f"  âš ï¸  ç”Ÿæˆç»“æœæ— æ•ˆï¼Œè·³è¿‡æ­¤æ ·æœ¬")
                        continue
                        
                except Exception as e:
                    if self.is_main_process:
                        print(f"  âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                        print(f"  ğŸ“Š è¾“å…¥å›¾åƒå½¢çŠ¶: {rgbxyz.shape}")
                        print(f"  ğŸ“Š è¾“å…¥å›¾åƒèŒƒå›´: [{rgbxyz.min().item():.4f}, {rgbxyz.max().item():.4f}]")
                    continue
                
                # è®¡ç®—ç”ŸæˆæŒ‡æ ‡
                gen_metrics = self._compute_generation_metrics(gen_results, targets, None, verbose=False)
                
                # åœ¨testæ¨ç†æ—¶æ‰“å°æ¯ä¸ªsampleçš„IoU
                if self.is_main_process:
                    print(f"   Test Sample {batch_idx + 1}: Mean IoU = {gen_metrics['iou']:.4f} ({gen_metrics['num_generated_boxes']:.0f} boxes)")
                
                # ç´¯ç§¯ç»Ÿè®¡
                total_gen_iou += gen_metrics['iou']
                total_generated_boxes += gen_metrics['num_generated_boxes']
                total_gt_boxes += gen_metrics['num_gt_boxes']
                total_x_error += gen_metrics['x_error']
                total_y_error += gen_metrics['y_error']
                total_z_error += gen_metrics['z_error']
                total_w_error += gen_metrics['w_error']
                total_h_error += gen_metrics['h_error']
                total_l_error += gen_metrics['l_error']
                total_overall_error += gen_metrics['overall_mean_error']
                
                # ä¿å­˜è¯¦ç»†ç»“æœ
                test_results.append({
                    'batch_idx': batch_idx,
                    'folder_name': batch['folder_name'][0] if 'folder_name' in batch else f'test_{batch_idx}',
                    'generation_results': {
                        'x': gen_results['x'].cpu().tolist() if 'x' in gen_results else [],
                        'y': gen_results['y'].cpu().tolist() if 'y' in gen_results else [],
                        'z': gen_results['z'].cpu().tolist() if 'z' in gen_results else [],
                        'w': gen_results['w'].cpu().tolist() if 'w' in gen_results else [],
                        'h': gen_results['h'].cpu().tolist() if 'h' in gen_results else [],
                        'l': gen_results['l'].cpu().tolist() if 'l' in gen_results else [],
                    },
                    'ground_truth': {
                        'x': targets['x'].cpu().tolist(),
                        'y': targets['y'].cpu().tolist(),
                        'z': targets['z'].cpu().tolist(),
                        'w': targets['w'].cpu().tolist(),
                        'h': targets['h'].cpu().tolist(),
                        'l': targets['l'].cpu().tolist(),
                        'rotations': targets['rotations'].cpu().tolist(),
                    },
                    'metrics': {
                        'iou': gen_metrics['iou'],
                        'num_generated_boxes': gen_metrics['num_generated_boxes'],
                        'num_gt_boxes': gen_metrics['num_gt_boxes'],
                        'x_error': gen_metrics['x_error'],
                        'y_error': gen_metrics['y_error'],
                        'z_error': gen_metrics['z_error'],
                        'w_error': gen_metrics['w_error'],
                        'h_error': gen_metrics['h_error'],
                        'l_error': gen_metrics['l_error'],
                        'overall_mean_error': gen_metrics['overall_mean_error']
                    }
                })
                
                num_batches += 1
        
        # è®¡ç®—å¹³å‡å€¼
        avg_gen_iou = total_gen_iou / num_batches if num_batches > 0 else 0.0
        avg_generated_boxes = total_generated_boxes / num_batches if num_batches > 0 else 0.0
        avg_gt_boxes = total_gt_boxes / num_batches if num_batches > 0 else 0.0
        avg_x_error = total_x_error / num_batches if num_batches > 0 else 0.0
        avg_y_error = total_y_error / num_batches if num_batches > 0 else 0.0
        avg_z_error = total_z_error / num_batches if num_batches > 0 else 0.0
        avg_w_error = total_w_error / num_batches if num_batches > 0 else 0.0
        avg_h_error = total_h_error / num_batches if num_batches > 0 else 0.0
        avg_l_error = total_l_error / num_batches if num_batches > 0 else 0.0
        avg_overall_error = total_overall_error / num_batches if num_batches > 0 else 0.0
        
        # ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶ - åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜
        if self.is_main_process:
            test_results_file = self.output_dir / "test_results.json"
            with open(test_results_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'test_summary': {
                        'num_samples': num_batches,
                        'avg_generation_iou': avg_gen_iou,
                        'avg_generated_boxes': avg_generated_boxes,
                        'avg_gt_boxes': avg_gt_boxes,
                        'avg_overall_error': avg_overall_error,
                        'avg_x_error': avg_x_error,
                        'avg_y_error': avg_y_error,
                        'avg_z_error': avg_z_error,
                        'avg_w_error': avg_w_error,
                        'avg_h_error': avg_h_error,
                        'avg_l_error': avg_l_error,
                        'generation_rate': avg_generated_boxes / max(avg_gt_boxes, 1)
                    },
                    'detailed_results': test_results
                }, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {test_results_file}")
        
        # æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦ - åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
        if self.is_main_process:
            print(f"\nğŸ§ª æµ‹è¯•é›†æ¨ç†ç»“æœæ‘˜è¦:")
            print(f"   æ ·æœ¬æ•°é‡: {num_batches}")
            print(f"   å¹³å‡ç”ŸæˆIoU: {avg_gen_iou:.4f}")
            print(f"   å¹³å‡ç”Ÿæˆç®±å­æ•°: {avg_generated_boxes:.1f}")
            print(f"   å¹³å‡GTç®±å­æ•°: {avg_gt_boxes:.1f}")
            print(f"   ç”Ÿæˆç‡: {avg_generated_boxes/max(avg_gt_boxes, 1):.2f}")
            print(f"   æ€»ä½“å¹³å‡è¯¯å·®: {avg_overall_error:.4f}")
            print(f"   Xè¯¯å·®: {avg_x_error:.4f} | Yè¯¯å·®: {avg_y_error:.4f} | Zè¯¯å·®: {avg_z_error:.4f}")
            print(f"   Wè¯¯å·®: {avg_w_error:.4f} | Hè¯¯å·®: {avg_h_error:.4f} | Lè¯¯å·®: {avg_l_error:.4f}")
        
        return {
            'generation_iou': avg_gen_iou,
            'avg_generated_boxes': avg_generated_boxes,
            'avg_gt_boxes': avg_gt_boxes,
            'avg_overall_error': avg_overall_error,
            'avg_x_error': avg_x_error,
            'avg_y_error': avg_y_error,
            'avg_z_error': avg_z_error,
            'avg_w_error': avg_w_error,
            'avg_h_error': avg_h_error,
            'avg_l_error': avg_l_error
        }
    
    def _save_checkpoint(self, is_best: bool = False, is_best_generation: bool = False):
        """ä¿å­˜checkpoint"""
        if not self.is_main_process:
            return
        checkpoint = {
            'model': self.model.module.state_dict() if hasattr(self.model, 'module') else self.model.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict() if self.scheduler else None,
            'scaler': self.scaler.state_dict() if self.scaler else None,
            'epoch': self.current_epoch,
            'current_phase_idx': self.current_phase_idx,
            'best_val_loss': self.best_val_loss,
            'best_generation_loss': self.best_generation_loss,
            'training_stats': self.training_stats,
            'model_config': self.model_config,
            'training_config': self.training_config,
            'metadata': {
                'total_epochs': sum(phase.epochs for phase in self.training_phases),
                'training_phases': [asdict(phase) for phase in self.training_phases],
                'device': str(self.device),
                'world_size': self.world_size,
                'local_rank': self.local_rank
            }
        }
        
        # åªä¿å­˜æœ€æ–°checkpoint (ç”¨äºresume)
        latest_path = self.checkpoint_dir / "checkpoint_latest.pt"
        torch.save(checkpoint, latest_path)
        
        # ä¿å­˜æœ€ä½³éªŒè¯æŸå¤±æ¨¡å‹
        if is_best:
            best_path = self.checkpoint_dir / "checkpoint_best_val.pt"
            torch.save(checkpoint, best_path)
            if self.is_main_process:
                print(f"âœ… æœ€ä½³éªŒè¯æ¨¡å‹å·²ä¿å­˜: {best_path}")
        
        # ä¿å­˜æœ€ä½³ç”Ÿæˆæ¨¡å‹
        if is_best_generation:
            best_gen_path = self.checkpoint_dir / "checkpoint_best_generation.pt"
            torch.save(checkpoint, best_gen_path)
            if self.is_main_process:
                print(f"âœ… æœ€ä½³ç”Ÿæˆæ¨¡å‹å·²ä¿å­˜: {best_gen_path}")
        
        if not (is_best or is_best_generation):
            if self.is_main_process:
                print(f"âœ… æœ€æ–°checkpointå·²ä¿å­˜: {latest_path}")
    
    def _load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½checkpoint"""
        if self.is_main_process:
            print(f"ğŸ“‚ åŠ è½½checkpoint: {checkpoint_path}")
        
        # ğŸ”§ ä¿®å¤PyTorch 2.6çš„weights_onlyé—®é¢˜
        # ç”±äºè¿™æ˜¯æˆ‘ä»¬è‡ªå·±çš„checkpointæ–‡ä»¶ï¼Œè®¾ç½®weights_only=Falseæ˜¯å®‰å…¨çš„
        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
        
        # åŠ è½½æ¨¡å‹çŠ¶æ€
        if hasattr(self.model, 'module'):
            self.model.module.load_state_dict(checkpoint['model'])
        else:
            self.model.load_state_dict(checkpoint['model'])
        
        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
        self.optimizer.load_state_dict(checkpoint['optimizer'])
        
        # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€
        if self.scheduler and checkpoint['scheduler']:
            self.scheduler.load_state_dict(checkpoint['scheduler'])
        
        # åŠ è½½scalerçŠ¶æ€
        if self.scaler and checkpoint['scaler']:
            self.scaler.load_state_dict(checkpoint['scaler'])
        
        # æ¢å¤è®­ç»ƒçŠ¶æ€
        self.current_epoch = checkpoint['epoch'] + 1  # ä»ä¸‹ä¸€ä¸ªepochå¼€å§‹
        self.current_phase_idx = checkpoint.get('current_phase_idx', 0)
        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        self.best_generation_loss = checkpoint.get('best_generation_loss', float('inf'))
        self.training_stats = checkpoint.get('training_stats', [])
        
        # ğŸ”§ ä¿®å¤ï¼šé‡æ–°è®¡ç®—æ­£ç¡®çš„è®­ç»ƒé˜¶æ®µï¼ˆä»¥é˜²checkpointä¸­çš„phase_idxä¸å‡†ç¡®ï¼‰
        epoch_count = 0
        old_phase_idx = self.current_phase_idx
        for phase_idx, phase in enumerate(self.training_phases):
            if self.is_main_process:
                print(f"   æ£€æŸ¥é˜¶æ®µ{phase_idx} ({phase.name}): epochs {epoch_count}-{epoch_count + phase.epochs - 1}")
                print(f"     æ¡ä»¶: {self.current_epoch} < {epoch_count + phase.epochs} = {self.current_epoch < epoch_count + phase.epochs}")
            
            if self.current_epoch < epoch_count + phase.epochs:
                self.current_phase_idx = phase_idx
                if self.is_main_process:
                    print(f"     -> é€‰æ‹©é˜¶æ®µ{phase_idx} ({phase.name})")
                break
            epoch_count += phase.epochs
        
        if self.is_main_process:
            print(f"ğŸ”„ é˜¶æ®µç´¢å¼•: {old_phase_idx} -> {self.current_phase_idx}")
            print(f"âœ… å·²æ¢å¤åˆ°epoch {self.current_epoch}")
            print(f"ğŸ¯ å½“å‰è®­ç»ƒé˜¶æ®µ: {self.training_phases[self.current_phase_idx].name} (é˜¶æ®µ{self.current_phase_idx})")
            print(f"ğŸ“Š æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
            print(f"ğŸ¯ æœ€ä½³ç”ŸæˆæŸå¤±: {self.best_generation_loss:.4f}")
    
    def _evaluate_best_model_on_test(self, is_best_val: bool = False, is_best_generation: bool = False):
        """åœ¨è·å¾—æœ€ä½³æ¨¡å‹æ—¶åœ¨testé›†ä¸Šè¿›è¡Œæ¨ç†å¹¶è®°å½•ç»“æœ"""
        if not self.is_main_process:
            return
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨æœ€ä½³æ¨¡å‹testæ¨ç†
        best_model_testing_config = self.training_config.get('optimizations', {}).get('best_model_testing', {})
        if not best_model_testing_config.get('enabled', True):
            return
        
        # åªæœ‰åœ¨è·å¾—æœ€ä½³æ¨¡å‹æ—¶æ‰è¿›è¡Œtestæ¨ç†
        if not (is_best_val or is_best_generation):
            return
            
        print(f"\nğŸ¯ æ£€æµ‹åˆ°{'æœ€ä½³éªŒè¯æ¨¡å‹' if is_best_val else ''}{'å’Œ' if is_best_val and is_best_generation else ''}{'æœ€ä½³ç”Ÿæˆæ¨¡å‹' if is_best_generation else ''}ï¼Œå¼€å§‹åœ¨testé›†ä¸Šè¿›è¡Œæ¨ç†...")
        
        # ä¿å­˜å½“å‰æ¨¡å‹çŠ¶æ€
        current_model_state = self.model.module.state_dict() if hasattr(self.model, 'module') else self.model.state_dict()
        
        try:
            # åœ¨testé›†ä¸Šè¿›è¡Œæ¨ç†
            test_results = self._test_inference()
            
            # è®°å½•testç»“æœåˆ°SwanLab
            if self.use_swanlab and best_model_testing_config.get('save_results', True):
                # ä¸ºæœ€ä½³éªŒè¯æ¨¡å‹è®°å½•testç»“æœ
                if is_best_val:
                    swanlab.log({
                        'test_best_val/generation_iou': test_results['generation_iou'],
                        'test_best_val/overall_mean_error': test_results.get('avg_overall_error', 0.0),
                        'test_best_val/x_error': test_results.get('avg_x_error', 0.0),
                        'test_best_val/y_error': test_results.get('avg_y_error', 0.0),
                        'test_best_val/z_error': test_results.get('avg_z_error', 0.0),
                        'test_best_val/w_error': test_results.get('avg_w_error', 0.0),
                        'test_best_val/h_error': test_results.get('avg_h_error', 0.0),
                        'test_best_val/l_error': test_results.get('avg_l_error', 0.0),
                        'test_best_val/avg_generated_boxes': test_results.get('avg_generated_boxes', 0.0),
                        'test_best_val/avg_gt_boxes': test_results.get('avg_gt_boxes', 0.0),
                        'test_best_val/generation_rate': test_results.get('avg_generated_boxes', 0.0) / max(test_results.get('avg_gt_boxes', 1), 1),
                        'test_best_val/epoch': self.current_epoch
                    }, step=self.current_epoch)
                
                # ä¸ºæœ€ä½³ç”Ÿæˆæ¨¡å‹è®°å½•testç»“æœ
                if is_best_generation:
                    swanlab.log({
                        'test_best_gen/generation_iou': test_results['generation_iou'],
                        'test_best_gen/overall_mean_error': test_results.get('avg_overall_error', 0.0),
                        'test_best_gen/x_error': test_results.get('avg_x_error', 0.0),
                        'test_best_gen/y_error': test_results.get('avg_y_error', 0.0),
                        'test_best_gen/z_error': test_results.get('avg_z_error', 0.0),
                        'test_best_gen/w_error': test_results.get('avg_w_error', 0.0),
                        'test_best_gen/h_error': test_results.get('avg_h_error', 0.0),
                        'test_best_gen/l_error': test_results.get('avg_l_error', 0.0),
                        'test_best_gen/avg_generated_boxes': test_results.get('avg_generated_boxes', 0.0),
                        'test_best_gen/avg_gt_boxes': test_results.get('avg_gt_boxes', 0.0),
                        'test_best_gen/generation_rate': test_results.get('avg_generated_boxes', 0.0) / max(test_results.get('avg_gt_boxes', 1), 1),
                        'test_best_gen/epoch': self.current_epoch
                    }, step=self.current_epoch)
            
            # æ‰“å°testç»“æœ
            print(f"ğŸ§ª Testé›†æ¨ç†ç»“æœ (Epoch {self.current_epoch}):")
            print(f"   ç”ŸæˆIoU: {test_results['generation_iou']:.4f}")
            print(f"   æ€»ä½“å¹³å‡è¯¯å·®: {test_results.get('avg_overall_error', 0.0):.4f}")
            print(f"   Xè¯¯å·®: {test_results.get('avg_x_error', 0.0):.4f} | Yè¯¯å·®: {test_results.get('avg_y_error', 0.0):.4f} | Zè¯¯å·®: {test_results.get('avg_z_error', 0.0):.4f}")
            print(f"   Wè¯¯å·®: {test_results.get('avg_w_error', 0.0):.4f} | Hè¯¯å·®: {test_results.get('avg_h_error', 0.0):.4f} | Lè¯¯å·®: {test_results.get('avg_l_error', 0.0):.4f}")
            print(f"   å¹³å‡ç”Ÿæˆæ•°é‡: {test_results.get('avg_generated_boxes', 0.0):.1f} | å¹³å‡GTæ•°é‡: {test_results.get('avg_gt_boxes', 0.0):.1f}")
            print(f"   ç”Ÿæˆç‡: {test_results.get('avg_generated_boxes', 0.0) / max(test_results.get('avg_gt_boxes', 1), 1):.2f}")
            
        except Exception as e:
            print(f"âŒ Testé›†æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            # ç¡®ä¿æ¨¡å‹çŠ¶æ€æ²¡æœ‰è¢«æ”¹å˜
            if hasattr(self.model, 'module'):
                self.model.module.load_state_dict(current_model_state)
            else:
                self.model.load_state_dict(current_model_state)

    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        # å¤šGPUåŒæ­¥ç‚¹ - ç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½å‡†å¤‡å¥½
        if self.world_size > 1 and torch.cuda.device_count() > 1:
            if torch.distributed.is_initialized():
                torch.distributed.barrier()
                if self.is_main_process:
                    print("âœ… æ‰€æœ‰è¿›ç¨‹åŒæ­¥å®Œæˆï¼Œå¼€å§‹è®­ç»ƒ...")
        
        if self.is_main_process:
            print("ğŸš€ å¼€å§‹åˆ†æ®µå¼è®­ç»ƒ...")
        
        total_epochs = sum(phase.epochs for phase in self.training_phases)
        
        # ğŸ”§ ä¿®å¤ï¼šä¸å†é‡æ–°è®¡ç®—é˜¶æ®µç´¢å¼•ï¼Œä½¿ç”¨_load_checkpointä¸­å·²æ­£ç¡®è®¡ç®—çš„å€¼
        for phase_idx in range(self.current_phase_idx, len(self.training_phases)):
            phase = self.training_phases[phase_idx]
            
            if self.is_main_process:
                print(f"\n{'='*60}")
                print(f"ğŸ¯ è®­ç»ƒé˜¶æ®µ: {phase.name}")
                print(f"ğŸ“ {phase.description}")
                print(f"â±ï¸  æŒç»­{phase.epochs}ä¸ªepochs")
                print(f"ğŸ² Teacher Forcing: {phase.teacher_forcing_ratio}")
                print(f"ğŸ“Š Scheduled Sampling: {phase.scheduled_sampling}")
                print(f"{'='*60}")
            
            # ä¸ºå½“å‰é˜¶æ®µåˆ›å»ºæŸå¤±å‡½æ•°
            loss_fn = self._create_loss_function(phase.name)
            loss_fn = loss_fn.to(self.device)
            
            # è®¡ç®—é˜¶æ®µå†…çš„èµ·å§‹epoch
            phase_start_epoch = sum(p.epochs for p in self.training_phases[:phase_idx])
            
            for epoch_in_phase in range(phase.epochs):
                if self.current_epoch < phase_start_epoch + epoch_in_phase:
                    continue  # è·³è¿‡å·²è®­ç»ƒçš„epoch
                
                # ğŸ”§ ä¿®å¤ï¼šè®¡ç®—æ­£ç¡®çš„é˜¶æ®µå†…epochä½ç½®
                actual_epoch_in_phase = self.current_epoch - phase_start_epoch + 1
                
                if self.is_main_process:
                    print(f"\n--- Epoch {self.current_epoch + 1}/{total_epochs} "
                          f"(Phase: {phase.name}, {actual_epoch_in_phase}/{phase.epochs}) ---")
                
                # è®­ç»ƒ
                train_stats = self._train_epoch(phase, epoch_in_phase, loss_fn)
                
                # éªŒè¯
                val_results = self._validate_epoch(loss_fn, phase)
                val_tf_loss = val_results['tf_total_loss']
                val_gen_iou = val_results['generation_iou']
                val_tf_iou = val_results['tf_mean_iou']
                
                # å®Œå–„ç»Ÿè®¡ä¿¡æ¯
                train_stats.val_loss = val_tf_loss
                train_stats.val_generation_loss = 1.0 - val_gen_iou  # å°†IoUè½¬æ¢ä¸ºæŸå¤±å½¢å¼ï¼ˆç”¨äºå…¼å®¹ç°æœ‰ä»£ç ï¼‰
                train_stats.val_mean_iou = val_tf_iou
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                is_best_val = val_tf_loss < self.best_val_loss
                # ä½¿ç”¨IoUåˆ¤æ–­æœ€ä½³ç”Ÿæˆæ¨¡å‹ï¼šæ›´é«˜çš„IoU = æ›´å¥½çš„æ¨¡å‹
                is_best_generation = val_gen_iou > (1.0 - self.best_generation_loss)
                
                if is_best_val:
                    self.best_val_loss = val_tf_loss
                if is_best_generation:
                    # æ›´æ–°æœ€ä½³ç”ŸæˆæŸå¤±ï¼ˆå­˜å‚¨ä¸º1-IoUçš„å½¢å¼ï¼Œä¿æŒä¸ç°æœ‰ä»£ç å…¼å®¹ï¼‰
                    self.best_generation_loss = 1.0 - val_gen_iou
                
                # SwanLabæ—¥å¿—è®°å½•
                if self.use_swanlab:
                    # è®­ç»ƒlossç»„ä»¶
                    swanlab.log({
                        'train/total_loss': train_stats.train_loss,
                        'train/classification_loss': train_stats.train_classification_loss,
                        'train/iou_loss': train_stats.train_iou_loss,
                        'train/delta_loss': train_stats.train_delta_loss,
                        'train/mean_iou': train_stats.train_mean_iou,
                        
                        # Teacher ForcingéªŒè¯lossç»„ä»¶  
                        'val/tf_total_loss': val_results['tf_total_loss'],
                        'val/tf_classification_loss': val_results['tf_classification_loss'],
                        'val/tf_iou_loss': val_results['tf_iou_loss'],
                        'val/tf_delta_loss': val_results['tf_delta_loss'],
                        'val/tf_eos_loss': val_results['tf_eos_loss'],
                        'val/tf_mean_iou': val_results['tf_mean_iou'],
                        
                        # AutoregressiveéªŒè¯lossç»„ä»¶
                        'val/ar_mean_iou': val_results['generation_iou'],
                        # ç”Ÿæˆç»Ÿè®¡
                        'val/generation_rate': val_results['avg_generated_boxes'] / max(val_results['avg_gt_boxes'], 1),
                        # ç»´åº¦è¯¯å·®æŒ‡æ ‡
                        'val/overall_mean_error': val_results.get('avg_overall_error', 0.0),
                        'val/x_error': val_results.get('avg_x_error', 0.0),
                        'val/y_error': val_results.get('avg_y_error', 0.0),
                        'val/z_error': val_results.get('avg_z_error', 0.0),
                        'val/w_error': val_results.get('avg_w_error', 0.0),
                        'val/h_error': val_results.get('avg_h_error', 0.0),
                        'val/l_error': val_results.get('avg_l_error', 0.0),
                        
                        # è®­ç»ƒå‚æ•°
                        'train/teacher_forcing_ratio': train_stats.teacher_forcing_ratio,
                        'train/learning_rate': train_stats.learning_rate,
                        'train/adaptive_cls_weight': train_stats.adaptive_cls_weight,
                        'train/adaptive_delta_weight': train_stats.adaptive_delta_weight,
                        
                        # epochä¿¡æ¯
                        # 'epoch': self.current_epoch,
                        # 'phase_idx': phase_idx,
                        'epoch_time': train_stats.epoch_time
                    }, step=self.current_epoch)  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ stepå‚æ•°ç¡®ä¿resumeæ—¶æ­£ç¡®ç»­æ¥

                # æ§åˆ¶å°è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                # æ§åˆ¶å°è¾“å‡ºè¯¦ç»†ä¿¡æ¯ - åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
                if self.is_main_process:
                    print(f"ğŸ“Š è®­ç»ƒæŸå¤±è¯¦æƒ…:")
                    print(f"   æ€»æŸå¤±: {train_stats.train_loss:.4f}")
                    print(f"   åˆ†ç±»æŸå¤±: {train_stats.train_classification_loss:.4f}")
                    print(f"   IoUæŸå¤±: {train_stats.train_iou_loss:.4f}")
                    print(f"   DeltaæŸå¤±: {train_stats.train_delta_loss:.4f}")
                    print(f"ğŸ¯ éªŒè¯æŸå¤±è¯¦æƒ…:")
                    print(f"   TFæ€»æŸå¤±: {val_results['tf_total_loss']:.4f}")
                    print(f"   TFåˆ†ç±»: {val_results['tf_classification_loss']:.4f} | TF IoU: {val_results['tf_iou_loss']:.4f} | TF Delta: {val_results['tf_delta_loss']:.4f} | TF EOS: {val_results['tf_eos_loss']:.4f}")
                    print(f"   TF mean IoU: {val_results['tf_mean_iou']:.4f}")
                    print(f"ğŸ“Š ç”Ÿæˆæ¨¡å¼è¯¦æƒ…:")
                    print(f"   ç”ŸæˆIoUè¯„ä¼°: {val_results['generation_iou']:.4f}")
                    print(f"ğŸ“ ç»´åº¦è¯¯å·®è¯¦æƒ…:")
                    print(f"   æ€»ä½“å¹³å‡è¯¯å·®: {val_results.get('avg_overall_error', 0.0):.4f}")
                    print(f"   Xè¯¯å·®: {val_results.get('avg_x_error', 0.0):.4f} | Yè¯¯å·®: {val_results.get('avg_y_error', 0.0):.4f} | Zè¯¯å·®: {val_results.get('avg_z_error', 0.0):.4f}")
                    print(f"   Wè¯¯å·®: {val_results.get('avg_w_error', 0.0):.4f} | Hè¯¯å·®: {val_results.get('avg_h_error', 0.0):.4f} | Lè¯¯å·®: {val_results.get('avg_l_error', 0.0):.4f}")
                    print(f"ğŸ“¦ ç®±å­ç»Ÿè®¡:")
                    print(f"   å¹³å‡ç”Ÿæˆæ•°é‡: {val_results['avg_generated_boxes']:.1f} | å¹³å‡GTæ•°é‡: {val_results['avg_gt_boxes']:.1f} | ç”Ÿæˆç‡: {val_results['avg_generated_boxes']/max(val_results['avg_gt_boxes'], 1):.2f}")
                    print(f"âš–ï¸  æƒé‡è¯¦æƒ…:")
                    print(f"   è‡ªé€‚åº”åˆ†ç±»æƒé‡: {train_stats.adaptive_cls_weight:.3f}")
                    print(f"   è‡ªé€‚åº”Deltaæƒé‡: {train_stats.adaptive_delta_weight:.3f}")
                    print(f"   TFæ¯”ä¾‹: {train_stats.teacher_forcing_ratio:.3f} | å­¦ä¹ ç‡: {train_stats.learning_rate:.2e}")
                
                # ä¿å­˜checkpoint
                if (self.current_epoch + 1) % self.training_config.get('save_interval', 10) == 0:
                    self._save_checkpoint(is_best_val, is_best_generation)
                elif is_best_val or is_best_generation:
                    self._save_checkpoint(is_best_val, is_best_generation)
                
                # åœ¨è·å¾—æœ€ä½³æ¨¡å‹æ—¶åœ¨testé›†ä¸Šè¿›è¡Œæ¨ç†
                self._evaluate_best_model_on_test(is_best_val, is_best_generation)
                
                self.current_epoch += 1
        
        if self.is_main_process:
            print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
            print(f"ğŸ“Š æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
            print(f"ğŸ¯ æœ€ä½³ç”ŸæˆæŸå¤±: {self.best_generation_loss:.4f}")
        
        # ä¿å­˜æœ€ç»ˆcheckpoint
        if self.is_main_process:
            self._save_checkpoint()
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨ç†ï¼ˆè®­ç»ƒç»“æŸæ—¶çš„æœ€ç»ˆè¯„ä¼°ï¼‰
        if self.is_main_process:
            print("\nğŸ§ª è®­ç»ƒç»“æŸï¼Œå¼€å§‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆæ¨ç†...")
        test_results = self._test_inference()
        
        # è®°å½•æµ‹è¯•ç»“æœåˆ°SwanLab
        if self.use_swanlab:
            swanlab.log({
                'test/generation_iou': test_results['generation_iou'],
                'test/overall_mean_error': test_results.get('avg_overall_error', 0.0),
                'test/x_error': test_results.get('avg_x_error', 0.0),
                'test/y_error': test_results.get('avg_y_error', 0.0),
                'test/z_error': test_results.get('avg_z_error', 0.0),
                'test/w_error': test_results.get('avg_w_error', 0.0),
                'test/h_error': test_results.get('avg_h_error', 0.0),
                'test/l_error': test_results.get('avg_l_error', 0.0),
                'test/avg_generated_boxes': test_results.get('avg_generated_boxes', 0.0),
                'test/avg_gt_boxes': test_results.get('avg_gt_boxes', 0.0),
                'test/generation_rate': test_results.get('avg_generated_boxes', 0.0) / max(test_results.get('avg_gt_boxes', 1), 1)
            }, step=self.current_epoch)  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ stepå‚æ•°
            swanlab.finish()


def setup_distributed(local_rank: int, world_size: int):
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ"""
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç¯å¢ƒå˜é‡è®¾ç½®
    if 'MASTER_ADDR' not in os.environ:
        os.environ['MASTER_ADDR'] = 'localhost'
    if 'MASTER_PORT' not in os.environ:
        os.environ['MASTER_PORT'] = '12355'
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print(f"âš ï¸  CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ")
        return False
    
    # æ£€æŸ¥GPUæ•°é‡
    if torch.cuda.device_count() < world_size:
        print(f"âš ï¸  GPUæ•°é‡({torch.cuda.device_count()})å°‘äºworld_size({world_size})ï¼Œæ— æ³•è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ")
        return False
    
    try:
        dist.init_process_group(
            backend='nccl',
            rank=local_rank,
            world_size=world_size
        )
        print(f"âœ… åˆ†å¸ƒå¼è®­ç»ƒåˆå§‹åŒ–æˆåŠŸ (Rank {local_rank}/{world_size})")
        return True
    except Exception as e:
        print(f"âŒ åˆ†å¸ƒå¼è®­ç»ƒåˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()


def main(
    config_dir: str = ".",
    experiment_name: str = "primitive_3d_exp",
    resume_from: Optional[str] = None,
    local_rank: int = 0,
    world_size: int = 1,
    validation_samples: List[int] = None
):
    """ä¸»è®­ç»ƒå‡½æ•°"""
    
    # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ
    distributed_success = False
    if world_size > 1:
        distributed_success = setup_distributed(local_rank, world_size)
        if not distributed_success:
            print(f"âš ï¸  åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®å¤±è´¥ï¼Œå›é€€åˆ°å•GPUæ¨¡å¼")
            world_size = 1
            local_rank = 0
    
    try:
        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(42 + local_rank)
        np.random.seed(42 + local_rank)
        random.seed(42 + local_rank)
        
        # åŠ è½½ç»Ÿä¸€é…ç½® - åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        config_loader = ConfigLoader()
        config_loader.load_unified_config(os.path.join(config_dir, "training_config.yaml"))
        
        if local_rank == 0:
            print(f"âœ… æˆåŠŸåŠ è½½ç»Ÿä¸€é…ç½®æ–‡ä»¶: {os.path.join(config_dir, 'training_config.yaml')}")
            # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
            global_config = config_loader.get_global_config()
            print(f"ğŸ“Š é…ç½®ç‰ˆæœ¬: {global_config.get('version', 'unknown')}")
            
            # æ˜¾ç¤ºè®­ç»ƒé˜¶æ®µä¿¡æ¯
            phases_config = config_loader.get_training_phases()
            total_epochs = sum(phase.get('epochs', 0) for phase in phases_config.values())
            print(f"ğŸ¯ è®­ç»ƒé˜¶æ®µ: {len(phases_config)}ä¸ªé˜¶æ®µï¼Œæ€»è®¡{total_epochs}ä¸ªepoch")
            for phase_name, phase_config in phases_config.items():
                print(f"  - {phase_name}: {phase_config.get('epochs', 0)} epochs")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = AdvancedTrainer(
            config_loader=config_loader,
            experiment_name=experiment_name,
            resume_from=resume_from,
            local_rank=local_rank,
            world_size=world_size,
            use_swanlab=True,
            validation_samples=validation_samples or [0, 1, 2, 3, 4]
        )
        
        # å¼€å§‹è®­ç»ƒ
        trainer.train()
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        raise
    finally:
        # æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒ
        if distributed_success:
            cleanup_distributed()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="3D Primitive Detection Training")
    parser.add_argument("--config-dir", default=".", help="é…ç½®æ–‡ä»¶ç›®å½•")
    parser.add_argument("--experiment-name", default="primitive_3d_exp", help="å®éªŒåç§°")
    parser.add_argument("--resume-from", default=None, help="æ¢å¤è®­ç»ƒçš„checkpointè·¯å¾„")
    parser.add_argument("--local-rank", type=int, default=0, help="æœ¬åœ°GPUæ’å")
    parser.add_argument("--world-size", type=int, default=1, help="æ€»GPUæ•°é‡")
    parser.add_argument("--validation-samples", nargs='+', type=int, default=[0, 1, 2, 3, 4], 
                       help="éªŒè¯å¯è§†åŒ–æ ·æœ¬ç´¢å¼•")
    
    args = parser.parse_args()
    
    main(
        config_dir=args.config_dir,
        experiment_name=args.experiment_name,
        resume_from=args.resume_from,
        local_rank=args.local_rank,
        world_size=args.world_size,
        validation_samples=args.validation_samples
    ) 